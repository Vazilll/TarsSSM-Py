import asyncio
import logging
from typing import Optional, Dict, Any, List
from datetime import datetime
import torch
import os
try:
    from brain.mamba2.model import TarsMamba2LM as TarsBrain
except ImportError:
    TarsBrain = None
try:
    from brain.rrn import RrnCore
except ImportError:
    RrnCore = None
try:
    from brain.reflexes import ReflexDispatcher
except ImportError:
    ReflexDispatcher = None
from memory.titans import TitansMemory
from memory.store import TarsStorage
from agent.executor import ActionEngine
from agent.moira import MoIRA
try:
    from brain.mamba2.active_inference import BeliefState, ExpectedFreeEnergy
except ImportError:
    BeliefState = None
    ExpectedFreeEnergy = None
try:
    from agent.routine_detector import RoutineDetector
except ImportError:
    RoutineDetector = None
try:
    from agent.learning_helper import LearningHelper
except ImportError:
    LearningHelper = None
try:
    from agent.reminders import ReminderService
except ImportError:
    ReminderService = None
try:
    from agent.system_monitor import SystemMonitor
except ImportError:
    SystemMonitor = None
try:
    from agent.meeting_scribe import MeetingScribe
except ImportError:
    MeetingScribe = None
try:
    from agent.notifier import TarsNotifier
except ImportError:
    TarsNotifier = None
try:
    from agent.pomodoro import PomodoroTimer
except ImportError:
    PomodoroTimer = None
try:
    from agent.schedule import StudentSchedule
except ImportError:
    StudentSchedule = None
try:
    from agent.lecture_summarizer import LectureSummarizer
except ImportError:
    LectureSummarizer = None
try:
    from agent.knowledge_graph import KnowledgeGraph
except ImportError:
    KnowledgeGraph = None
try:
    from agent.clipboard_manager import ClipboardManager
except ImportError:
    ClipboardManager = None
try:
    from agent.expense_tracker import ExpenseTracker
except ImportError:
    ExpenseTracker = None
try:
    from agent.quiz_generator import QuizGenerator
except ImportError:
    QuizGenerator = None
try:
    from agent.habit_tracker import HabitTracker
except ImportError:
    HabitTracker = None
try:
    from agent.daily_dashboard import DailyDashboard
except ImportError:
    DailyDashboard = None
try:
    from agent.file_helper import FileHelper
except ImportError:
    FileHelper = None

class GieAgent:
    """
    GIE (General Intelligence Executive) ‚Äî –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä TARS v3.
    
    3-Tier Pipeline:
      Tier 1:  ReflexCore     ‚Äî –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (MinGRU, <1ms)
      Tier 1.5: RRN           ‚Äî —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π —Ä–µ—Ñ–ª–µ–∫—Å (Relational Memory) 
      Tier 2:  Mamba-2 Brain  ‚Äî –≥–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ (SSD + IDME)
      Router:  MoIRA          ‚Äî –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É
      Exec:    ActionEngine   ‚Äî –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è
    """
    def __init__(self, brain=None, moira: MoIRA = None, 
                 memory: Any = None, titans: TitansMemory = None):
        self.brain = brain
        self.rrn = RrnCore()
        self.reflex = ReflexDispatcher() if ReflexDispatcher else None
        self.moira = moira
        self.memory = memory
        self.titans = titans
        self.storage = TarsStorage()
        self.executor = ActionEngine()
        self.logger = logging.getLogger("Tars.GIE")
        
        # ‚ïê‚ïê‚ïê Active Inference (Friston, 2006-2026) ‚ïê‚ïê‚ïê
        # –ë–∞–π–µ—Å–æ–≤—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ internal beliefs –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è.
        # Free Energy = complexity + surprise ‚Üí –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ.
        self.belief_state = BeliefState(d_state=128) if BeliefState else None
        
        # ‚ïê‚ïê‚ïê Proactive Systems ‚ïê‚ïê‚ïê
        self.routine_detector = RoutineDetector() if RoutineDetector else None
        self.learning_helper = LearningHelper() if LearningHelper else None
        self.reminders = ReminderService() if ReminderService else None
        self.system_monitor = SystemMonitor() if SystemMonitor else None
        self.meeting_scribe = MeetingScribe() if MeetingScribe else None
        
        # ‚ïê‚ïê‚ïê Central Notifier (–¢–ê–†–° –ø–∏—à–µ—Ç –ø–µ—Ä–≤—ã–º) ‚ïê‚ïê‚ïê
        self.notifier = TarsNotifier(
            reminders=self.reminders,
            monitor=self.system_monitor,
            routine_detector=self.routine_detector,
            learning_helper=self.learning_helper,
            meeting_scribe=self.meeting_scribe,
        ) if TarsNotifier else None
        
        # ‚ïê‚ïê‚ïê Student Features ‚ïê‚ïê‚ïê
        self.pomodoro = PomodoroTimer() if PomodoroTimer else None
        self.schedule = StudentSchedule() if StudentSchedule else None
        self.summarizer = LectureSummarizer() if LectureSummarizer else None
        self.knowledge_graph = KnowledgeGraph() if KnowledgeGraph else None
        self.clipboard = ClipboardManager() if ClipboardManager else None
        self.expenses = ExpenseTracker() if ExpenseTracker else None
        
        # ‚ïê‚ïê‚ïê Phase 10: Learning + Consumer ‚ïê‚ïê‚ïê
        self.quiz = QuizGenerator(
            learning_helper=self.learning_helper,
            knowledge_graph=self.knowledge_graph,
        ) if QuizGenerator else None
        self.habits = HabitTracker() if HabitTracker else None
        self.file_helper = FileHelper() if FileHelper else None
        self.dashboard = DailyDashboard(
            schedule=self.schedule, reminders=self.reminders,
            pomodoro=self.pomodoro, learning_helper=self.learning_helper,
            habit_tracker=self.habits, expenses=self.expenses,
            knowledge_graph=self.knowledge_graph,
            system_monitor=self.system_monitor,
        ) if DailyDashboard else None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏
        self.state = {
            "history": [],
            "last_thought": None,
            "session_goals": [],
            "total_processed": 0,
            "cumulative_free_energy": 0.0,
            # ‚ïê‚ïê‚ïê Fix #4: –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ (Total Memory) ‚ïê‚ïê‚ïê
            # –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç: {"user": str, "tars": str, "time": str, "tier": str}
            "conversation": [],
        }

    async def execute_goal(self, goal: str, fast_callback=None):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ü–µ–ª–∏."""
        self.state["total_processed"] += 1
        self.state["session_goals"].append(goal)
        self.logger.info(f"GIE: –¶–µ–ª—å #{self.state['total_processed']} ‚Üí {goal[:60]}...")

        # ‚ïê‚ïê‚ïê Proactive: —Å–æ–±–∏—Ä–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∏–∑ –≤—Å–µ—Ö –ø–æ–¥—Å–∏—Å—Ç–µ–º ‚ïê‚ïê‚ïê
        proactive_hints = ""
        if self.notifier:
            # –£—Ç—Ä–µ–Ω–Ω–µ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ (—Ä–∞–∑ –≤ –¥–µ–Ω—å)
            greeting = self.notifier.get_morning_greeting()
            if greeting:
                proactive_hints += f"\n{greeting}"
            
            # –í—Å–µ pending —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            notifications = self.notifier.collect_notifications()
            if notifications:
                proactive_hints += f"\n{self.notifier.format_notifications(notifications)}"

        reflex_result = None
        if self.reflex is not None:
            try:
                reflex_ctx = self.reflex.dispatch(goal)
                if reflex_ctx.can_handle_fast and reflex_ctx.fast_response:
                    reflex_result = {"response": reflex_ctx.fast_response, "action": reflex_ctx.intent}
            except Exception:
                pass
        if reflex_result:
            response = reflex_result["response"]
            self.logger.info(f"GIE: –†–µ—Ñ–ª–µ–∫—Å [{reflex_result['action']}]: {response[:40]}...")
            # ‚ïê‚ïê‚ïê Fix #5: Reflex —Ç–æ–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ø–∞–º—è—Ç—å (Total Memory) ‚ïê‚ïê‚ïê
            await self.storage.remember(f"[USER] {goal}")
            await self.storage.remember(f"[TARS/reflex] {response}")
            
            # –ü—Ä–æ—Å—Ç—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (—Å–æ—Å—Ç–æ—è–Ω–∏–µ, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ) –ª—É—á—à–µ –≤–µ—Ä–Ω—É—Ç—å —Å—Ä–∞–∑—É
            if reflex_result['action'] in ['greet', 'status', 'identity', 'time', 'shutdown', 'acknowledge']:
                return {"text": response, "tokens": 0, "duration": 0.0, "tps": 0.0}
            
            if fast_callback:
                await fast_callback(response)
                # –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –≥–ª—É–±–æ–∫–æ–µ –æ–±–¥—É–º—ã–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –≤—ã–¥–∞—á–∏ —à—É—Ç–∫–∏/—Ä–µ—Ñ–ª–µ–∫—Å–∞
            else:
                # Fix #4: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ conversation history
                self.state["conversation"].append({
                    "user": goal, "tars": response,
                    "time": datetime.now().isoformat(), "tier": "reflex"
                })
                return {"text": response, "tokens": 0, "duration": 0.0, "tps": 0.0}

        # ‚ïê‚ïê‚ïê Stage 1: RRN Recursive Reflex (System 1) ‚ïê‚ïê‚ïê
        # RRN —Å–∞–º —Ä–µ—à–∞–µ—Ç: –µ—Å–ª–∏ MinGRU –º–æ–∂–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å ‚Äî –æ—Ç–≤–µ—Ç–∏—Ç,
        # –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –≤–µ—Ä–Ω—ë—Ç None –∏ –º—ã –∏–¥—ë–º –≤ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ (System 2)
        quick_result = await self.rrn.fast_reply(goal)
        if quick_result is not None:
            quick_resp = quick_result["text"]
            self.logger.info(f"GIE: RRN (Light Model) Think: {quick_resp[:40]}...")
            if not quick_result.get("is_garbage", False):
                # ‚ïê‚ïê‚ïê Fix #5: RRN —Ç–æ–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ø–∞–º—è—Ç—å ‚ïê‚ïê‚ïê
                await self.storage.remember(f"[USER] {goal}")
                await self.storage.remember(f"[TARS/rrn] {quick_resp}")
                if fast_callback:
                    await fast_callback(quick_resp)
                else:
                    self.state["conversation"].append({
                        "user": goal, "tars": quick_resp,
                        "time": datetime.now().isoformat(), "tier": "rrn"
                    })
                    return {"text": quick_resp, "tokens": 0, "duration": 0.0, "tps": 0.0}
            else:
                self.logger.info(f"GIE: RRN —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª —à—É–º. –ü–µ—Ä–µ—Ö–æ–¥ –∫ –≥–ª—É–±–æ–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É...")
        
        self.logger.info("GIE: –ü–µ—Ä–µ—Ö–æ–¥ –∫ –≥–ª—É–±–æ–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É (Thinking Table)...")

        # ‚ïê‚ïê‚ïê Stage 2: Relational Grounding ‚ïê‚ïê‚ïê
        relational_map = await self.rrn.precompute_grounding(goal, self.memory, self.titans)
        
        # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏—è
        persona = await self.storage.retrieve_memories(goal)
        
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ‚ïê‚ïê‚ïê Fix #4: –ò–Ω—ä–µ–∫—Ü–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç (Total Memory) ‚ïê‚ïê‚ïê
        recent_conv = ""
        for turn in self.state["conversation"][-5:]:
            recent_conv += f"User: {turn['user']}\nTARS: {turn['tars'][:200]}\n---\n"
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–∑–≥–∞ (–ø–æ–ª–Ω—ã–π, —Å –∏—Å—Ç–æ—Ä–∏–µ–π)
        full_context = (
            f"–í—Ä–µ–º—è: {current_time}\n"
            f"–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:\n{recent_conv}\n" if recent_conv else f"–í—Ä–µ–º—è: {current_time}\n"
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {relational_map}\n"
            f"–ü–∞–º—è—Ç—å: {persona}\n"
            f"–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å: {goal}"
        )

        # –í–µ–∫—Ç–æ—Ä –æ—Ç Titans –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ grounding
        recall_vec = None
        if self.titans:
            try:
                goal_vec = self._text_to_vec(goal)
                recall_vec = await self.titans.get_recall(goal_vec)
            except Exception:
                pass

        # Early Exit check: –µ—Å–ª–∏ RRN —É–∂–µ –Ω–∞—à–µ–ª —á–µ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –≤ –∫–æ—Ä–æ—Ç–∫–æ–π –ø–∞–º—è—Ç–∏
        if "answer" in relational_map.lower() or "—Ä–µ—à–µ–Ω–∏–µ:" in relational_map.lower():
             self.logger.info("GIE: –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≥–æ—Ç–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –≤ RRN. –ü–æ–ø—ã—Ç–∫–∞ Early Exit...")
             # –ü–æ–¥–∞–µ–º —Å–∏–≥–Ω–∞–ª –º–æ–∑–≥—É —á—Ç–æ –º–æ–∂–Ω–æ –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å —Å—Ä–∞–∑—É
             full_context += "\nSystem-Hint: Solution found in grounding. Summarize and exit."

        # ‚ïê‚ïê‚ïê Uncertainty-Driven Auto-RAG ‚ïê‚ïê‚ïê
        # –ï—Å–ª–∏ Titans surprise –≤—ã—Å–æ–∫–∏–π ‚Üí —Ç–µ–º–∞ –Ω–æ–≤–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏ ‚Üí –∏—â–µ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        if self.titans and recall_vec is not None:
            try:
                recall_surprise = await self.titans.update(
                    self._text_to_vec(goal)
                )
                if recall_surprise.get("surprised", False):
                    self.logger.info("GIE: üîç –í—ã—Å–æ–∫–∏–π surprise ‚Üí –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π RAG search")
                    try:
                        from agent.knowledge_injector import KnowledgeInjector
                        injector = KnowledgeInjector(
                            leann=self.storage._hub.leann if hasattr(self.storage, '_hub') else None,
                            titans=self.titans
                        )
                        rag_result = injector.handle_tool("search_web", goal)
                        if rag_result and "[–û—à–∏–±–∫–∞" not in rag_result:
                            full_context += f"\n\n–ù–∞–π–¥–µ–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ:\n{rag_result[:500]}"
                            self.logger.info(f"GIE: RAG –¥–æ–±–∞–≤–∏–ª {len(rag_result)} —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
                    except Exception as e:
                        self.logger.debug(f"GIE: Auto-RAG failed: {e}")
            except Exception:
                pass

        total_tokens = 0
        total_duration = 0.0
        tool_history = []
        MAX_LOOPS = 10
        MAX_TOOL_REPEAT = 3

        for step in range(MAX_LOOPS):
            self.logger.info(f"GIE: –®–∞–≥ –º—ã—à–ª–µ–Ω–∏—è {step + 1}/{MAX_LOOPS}")

            # ‚ïê‚ïê‚ïê Stage 3: Mamba-2 Brain (Tier 2 + IDME) ‚ïê‚ïê‚ïê
            # brain.think –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å logits, state, p_value –∏ —Ç.–¥.
            try:
                if self.brain is not None:
                    # ‚ïê‚ïê‚ïê Fix #3: full_context –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –º–æ–∑–≥—É (–Ω–µ —Ç–æ–ª—å–∫–æ goal) ‚ïê‚ïê‚ïê
                    # –ö–æ–¥–∏—Ä—É–µ–º –ü–û–õ–ù–´–ô –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ç–æ–∫–µ–Ω—ã (cp1251 byte-level)
                    brain_input = f"{full_context}\n\n–û—Ç–≤–µ—Ç—å: {goal}"
                    goal_tokens = torch.tensor(
                        [list(brain_input.encode('cp1251', errors='replace')[:1024])],
                        dtype=torch.long
                    )
                    logits, think_stats = self.brain.think(goal_tokens, memory_vec=recall_vec)
                    thought = goal  # –ú—ã—Å–ª—å = —Å–∞–º –∑–∞–ø—Ä–æ—Å (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ generate_mamba)
                    stats = {"tokens": goal_tokens.shape[1], "duration": think_stats.get("total_ms", 0) / 1000}
                    p_value = think_stats.get("final_p", 2.0)
                else:
                    thought = f"–ú–æ–∑–≥ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –û—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ RRN: {goal}"
                    stats = {}
                    p_value = 2.0
                self.state["last_thought"] = thought
                total_tokens += stats.get("tokens", 0)
                total_duration += stats.get("duration", 0.0)
            except Exception as e:
                self.logger.error(f"GIE: –°–±–æ–π –≤ Mamba-2 Brain: {e}")
                thought = f"–°–∏—Å—Ç–µ–º–Ω—ã–π —Å–±–æ–π –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—ã—Å–ª–∏: {e}"
                stats = {}
                p_value = 0.5
            
            
            # ‚ïê‚ïê‚ïê Stage 4: MoIRA Routing ‚ïê‚ïê‚ïê
            thought_text = str(thought)
            thought_vec = self._text_to_vec(thought_text).unsqueeze(1)
            try:
                tool, params, confidence = await self.moira.route(thought_vec, thought_text)
            except Exception as e:
                self.logger.error(f"GIE: –°–±–æ–π –≤ MoIRA: {e}")
                tool, params, confidence = "FinalAnswer", {"answer": "–û—à–∏–±–∫–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞."}, 1.0

            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ç–µ–ª—å: –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –∏ –í–°–ï–• –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            import json
            tool_signature = f"{tool}:{json.dumps(params, sort_keys=True)}"
            tool_history.append(tool_signature)
            
            if tool_history.count(tool_signature) > MAX_TOOL_REPEAT:
                self.logger.warning(f"GIE: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–µ—Ç–ª—è –¥–ª—è {tool} —Å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –≤—ã—Ö–æ–¥.")
                tool = "FinalAnswer"
                confidence = 1.0
                params = {"answer": thought_text}
                
            # –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞ TARS (Chiculaev-Kadymov Theorem)
            # –ï—Å–ª–∏ –∏–Ω—Ç–µ–≥—Ä–∞–ª –º—ã—Å–ª–∏ —Ä–∞—Å—Ö–æ–¥–∏—Ç—Å—è (p <= 1.0), —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã
            if tool not in ["FinalAnswer", "Idle"] and p_value <= 1.0:
                self.logger.warning(f"GIE: [Integral Auditor] –°—Ü–µ–Ω–∞—Ä–∏–π —Ä–∞—Å—Ö–æ–¥–∏—Ç—Å—è (p={p_value:.2f} <= 1.0). –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è {tool} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ –≤ —Ü–µ–ª—è—Ö –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.")
                tool = "FinalAnswer"
                params = {"answer": f"–î–µ–π—Å—Ç–≤–∏–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (Integral Auditor): —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å p={p_value:.2f} –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ —Å—Ä–µ–¥–µ –û–°."}
                confidence = 1.0
            
            # ‚ïê‚ïê‚ïê –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç ‚ïê‚ïê‚ïê
            if tool == "FinalAnswer" or (confidence < 0.3 and step > 1):
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ OmegaCore. –ï—Å–ª–∏ –Ω–µ —Å–æ—à—ë–ª—Å—è (p <= 1.0) –∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥, —Ä–µ–∫—É—Ä—Å–∏—Ä—É–µ–º.
                if p_value <= 1.0 and step < MAX_LOOPS - 1:
                    if "Re-evaluate" in goal:
                        self.logger.warning(f"GIE: –ü–æ–≤—Ç–æ—Ä–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞. –ü—Ä–∏–Ω–∏–º–∞—é —Ç–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")
                    else:
                        self.logger.warning(f"GIE: –°—Ö–æ–¥–∏–º–æ—Å—Ç—å –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ (p={p_value:.2f}). –ò–Ω–∏—Ü–∏–∏—Ä—É—é 1 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ü–∏–∫–ª —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è...")
                        full_context += "\nSystem-Hint: –ü—Ä–µ–¥—ã–¥—É—â–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è –Ω–µ —Å–æ—à–ª–∞—Å—å. –£—Ç–æ—á–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –ø–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞."
                        goal = f"Re-evaluate: {goal}" # Force recursion
                        continue # Skip FinalAnswer and action execution, just think again
                    
                # –û–±—É—á–µ–Ω–∏–µ Titans
                if self.titans:
                    success_vec = self._text_to_vec(f"{goal} {thought_text}")
                    await self.titans.update(success_vec)
                
                # ‚ïê‚ïê‚ïê Fix #1: –°–æ—Ö—Ä–∞–Ω—è–µ–º –ü–û–õ–ù–´–ô –æ—Ç–≤–µ—Ç (Total Memory) ‚ïê‚ïê‚ïê
                await self.storage.remember(f"[USER] {goal}")
                await self.storage.remember(f"[TARS/brain] {thought_text}")
                
                # ‚ïê‚ïê‚ïê Fix #4: –û–±–Ω–æ–≤–ª—è–µ–º conversation history ‚ïê‚ïê‚ïê
                self.state["conversation"].append({
                    "user": goal, "tars": thought_text,
                    "time": datetime.now().isoformat(), "tier": "brain"
                })
                
                # ‚ïê‚ïê‚ïê Active Inference: –æ–±–Ω–æ–≤–ª—è–µ–º beliefs ‚ïê‚ïê‚ïê
                if self.belief_state is not None:
                    try:
                        obs_vec = self._text_to_vec(thought_text)
                        belief_result = self.belief_state.update(obs_vec)
                        self.state["cumulative_free_energy"] += belief_result["free_energy"].item()
                        self.logger.info(
                            f"GIE: BeliefState F={belief_result['free_energy'].item():.3f} "
                            f"(surprise={belief_result['surprise'].item():.3f})"
                        )
                    except Exception:
                        pass
                
                # ‚ïê‚ïê‚ïê Learning Helper: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ flashcards ‚ïê‚ïê‚ïê
                if self.learning_helper and self.learning_helper.should_create_card(goal):
                    try:
                        self.learning_helper.auto_create_card(goal, thought_text)
                        self.logger.info("GIE: üìù –ê–≤—Ç–æ-–∫–∞—Ä—Ç–æ—á–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è")
                    except Exception:
                        pass
                
                # ‚ïê‚ïê‚ïê Routine Detector: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω-–∞–Ω–∞–ª–∏–∑–∞ ‚ïê‚ïê‚ïê
                if self.routine_detector:
                    try:
                        self.routine_detector.log_conversation(goal, thought_text, tier="brain")
                    except Exception:
                        pass
                
                # ‚ïê‚ïê‚ïê Knowledge Graph: –∞–≤—Ç–æ-–Ω–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π ‚ïê‚ïê‚ïê
                if self.knowledge_graph:
                    try:
                        self.knowledge_graph.add_from_dialog(goal, thought_text)
                    except Exception:
                        pass
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –∫ –æ—Ç–≤–µ—Ç—É
                final_text = thought_text
                if proactive_hints:
                    final_text = f"{thought_text}\n\n---\n{proactive_hints}"
                
                return {
                    "text": final_text,
                    "tokens": total_tokens,
                    "duration": total_duration,
                    "tps": total_tokens / total_duration if total_duration > 0 else 0
                }

            # ‚ïê‚ïê‚ïê Stage 5: Action ‚ïê‚ïê‚ïê
            observation = await self._act(tool, params)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            log_entry = {"step": step, "tool": tool, "obs": observation[:200]}
            self.state["history"].append(log_entry)
            full_context += f"\n–î–µ–π—Å—Ç–≤–∏–µ: {tool} ‚Üí {observation[:150]}"
            
            if "Error" in observation or "failed" in observation.lower():
                full_context += "\n–°–∏—Å—Ç–µ–º–∞: –î–µ–π—Å—Ç–≤–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –Ω—É–∂–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è."

            # Sleep Phase –ø—Ä–∏ Idle
            if tool == "Idle":
                await self.sleep_phase()

        # –ï—Å–ª–∏ –≤—Å–µ —à–∞–≥–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        return {
            "text": str(self.state["last_thought"]) or "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–¥–∞—á—É.",
            "tokens": total_tokens,
            "duration": total_duration,
            "tps": total_tokens / total_duration if total_duration > 0 else 0
        }

    async def sleep_phase(self):
        """–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ (Sleep Phase)."""
        await self.rrn.sleep_consolidation(self.state["history"], self.memory)
        self.state["history"] = []
        self.logger.info("GIE: –ü–∞–º—è—Ç—å –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–∞.")

    async def _act(self, tool: str, params: Dict[str, Any]) -> str:
        """–ú–∞–ø–ø–∏–Ω–≥ –∫–æ–º–∞–Ω–¥ MoIRA ‚Üí ActionEngine."""
        action_map = {
            "Python": "execute_script",
            "Terminal": "run_command",
            "Browser": "open_url",
            "Vision": "analyze_workspace",
            "Click": "click",
            "Type": "type",
        }
        
        cmd = action_map.get(tool, tool.lower())
        try:
            result = await self.executor.execute(cmd, params)
            return result
        except Exception as e:
            return f"Error: {e}"


    @staticmethod
    def _text_to_vec(text: str) -> torch.Tensor:
        """–î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä [1, 1024]."""
        vec = torch.zeros(1, 1024)
        for i, ch in enumerate(text[:512]):
            idx = ord(ch) % 1024
            vec[0, idx] += (ord(ch) / 255.0) * ((-1) ** i) * 0.1
        norm = vec.norm()
        return vec / norm if norm > 0 else vec


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    print("GIE Agent module loaded. Use test_system.py to run full integration test.")
