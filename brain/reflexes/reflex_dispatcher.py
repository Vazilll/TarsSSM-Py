"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ReflexDispatcher â€” ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ‚Ñ‡ĞµÑ€ ÑĞ¿Ğ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ·Ğ³Ğ°
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ 6 ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ñ‡ĞµÑ€ĞµĞ· ThreadPoolExecutor.
Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² ReflexContext â€” Ğ¾Ğ±Ğ¾Ğ³Ğ°Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ
Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ·Ğ³Ğ° (TarsMamba2LM).

ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:
  1. ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
  2. ReflexDispatcher.dispatch(query) â†’ 6 ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾ (<100Ğ¼Ñ)
  3. Ğ•ÑĞ»Ğ¸ Ñ€ĞµÑ„Ğ»ĞµĞºÑÑ‹ Ñ€ĞµÑˆĞ¸Ğ»Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ (greeting/time) â†’ Ğ¼Ğ³Ğ½Ğ¾Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
  4. Ğ˜Ğ½Ğ°Ñ‡Ğµ â†’ ReflexContext Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‘Ñ‚ÑÑ Ğ² TarsMamba2LM.think()
     Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ¾Ğ¹, RAG-ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ¸ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
  dispatcher = ReflexDispatcher()
  ctx = dispatcher.dispatch("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?")
  
  if ctx.can_handle_fast:
      print(ctx.fast_response)
  else:
      logits, stats = brain.think(tokens, ctx=ctx)
"""

import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any

from brain.reflexes.sensors import (
    IntentSensor,
    ComplexitySensor,
    RAGSensor,
    SystemSensor,
    EmotionSensor,
    ContextSensor,
    VoiceSensor,
)

logger = logging.getLogger("Tars.ReflexDispatcher")


@dataclass
class ReflexContext:
    """
    ĞĞ±Ğ¾Ğ³Ğ°Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²ÑĞµĞ¼Ğ¸ ÑĞµĞ½ÑĞ¾Ñ€Ğ°Ğ¼Ğ¸.
    ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‘Ñ‚ÑÑ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ·Ğ³ Ğ´Ğ»Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸.
    """
    
    # â•â•â• Timing â•â•â•
    query: str = ""
    dispatch_time_ms: float = 0.0
    sensor_times: Dict[str, float] = field(default_factory=dict)
    
    # â•â•â• Intent (Sensor 1) â•â•â•
    intent: str = "complex"
    confidence: float = 0.0
    can_handle_fast: bool = False
    fast_response: Optional[str] = None
    
    # â•â•â• Complexity (Sensor 2) â•â•â•
    estimated_depth: int = 12
    complexity_level: str = "complex"
    needs_idme: bool = True
    max_expansion_rounds: int = 12
    
    # â•â•â• RAG (Sensor 3) â•â•â•
    rag_found: bool = False
    rag_snippets: List[str] = field(default_factory=list)
    memory_vec: Any = None  # torch.Tensor or None
    
    # â•â•â• System (Sensor 4) â•â•â•
    cpu_percent: float = 0.0
    ram_free_gb: float = 0.0
    gpu_available: bool = False
    recommended_device: str = "cpu"
    
    # â•â•â• Emotion (Sensor 5) â•â•â•
    dominant_emotion: str = "neutral"
    urgency: float = 0.0
    
    # â•â•â• Context (Sensor 6) â•â•â•
    is_followup: bool = False
    session_length: int = 0
    context_summary: str = ""
    
    # â•â•â• Voice/Intonation (Sensor 7) â•â•â•
    voice_emotion: str = "neutral"
    voice_is_question: bool = False
    voice_pitch_trend: str = "flat"
    voice_energy: float = 0.0
    is_supplement: bool = False
    has_voice_data: bool = False
    
    def summary_line(self) -> str:
        """ĞšÑ€Ğ°Ñ‚ĞºĞ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° Ğ´Ğ»Ñ CLI."""
        emoji_map = {
            "greeting": "ğŸ‘‹", "farewell": "ğŸ‘‹", "status": "ğŸ“Š",
            "time": "â°", "action": "âš¡", "code": "ğŸ’»",
            "math": "ğŸ”¢", "complex": "ğŸ§ ", "neutral": "ğŸ’¬",
            "identity": "ğŸ¤–", "abilities": "ğŸ’ª", "thanks": "ğŸ˜Š",
        }
        emoji = emoji_map.get(self.intent, "ğŸ’¬")
        
        parts = [
            f"{emoji} {self.intent}({self.confidence:.0%})",
            f"depth={self.estimated_depth}",
            f"{self.complexity_level}",
        ]
        if self.rag_found:
            parts.append(f"RAG:{len(self.rag_snippets)}docs")
        if self.urgency > 0.3:
            parts.append(f"âš ï¸urgent={self.urgency:.0%}")
        if self.is_followup:
            parts.append("â†©ï¸followup")
        if self.is_supplement:
            parts.append("ğŸ¤supplement")
        if self.has_voice_data:
            parts.append(f"ğŸ—£{self.voice_emotion}")
        
        return " | ".join(parts)


class ReflexDispatcher:
    """
    ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ‚Ñ‡ĞµÑ€: Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ²ÑĞµ ÑĞµĞ½ÑĞ¾Ñ€Ñ‹ Ñ‡ĞµÑ€ĞµĞ· ThreadPool
    Ğ¸ ÑĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² ReflexContext.
    
    Ğ¢Ğ¸Ğ¿Ğ¸Ñ‡Ğ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ: <50ms Ğ´Ğ»Ñ 6 ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ² (Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼Ñƒ Ñ‡Ñ‚Ğ¾ CPU-bound
    Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºÑ€Ğ¾ÑˆĞµÑ‡Ğ½Ñ‹Ğµ, Ğ° ThreadPool Ğ¼Ğ°ÑĞºĞ¸Ñ€ÑƒĞµÑ‚ I/O Ğ¾Ñ‚ SystemSensor).
    """
    
    def __init__(self, memory=None, max_workers: int = 6):
        """
        Args:
            memory: TarsMemory (LEANN) instance Ğ´Ğ»Ñ RAGSensor.
                    None = RAG Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ñ‘Ğ½.
            max_workers: ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼Ğ°.
        """
        self.sensors = {
            "intent": IntentSensor(),
            "complexity": ComplexitySensor(),
            "rag": RAGSensor(memory=memory),
            "system": SystemSensor(),
            "emotion": EmotionSensor(),
            "context": ContextSensor(),
            "voice": VoiceSensor(),
        }
        self.max_workers = max_workers
        self.total_dispatches = 0
        self.total_fast_handled = 0
        
        logger.info(
            f"ReflexDispatcher: {len(self.sensors)} ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ², "
            f"{max_workers} Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²"
        )
    
    def dispatch(self, query: str, intonation_data: dict = None) -> ReflexContext:
        """
        ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµÑ… ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ².
        
        Args:
            query: Ğ¢ĞµĞºÑÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            intonation_data: Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚ IntonationSensor (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
        
        Returns:
            ReflexContext Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ²ÑĞµÑ… ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ²
        """
        t0 = time.perf_counter()
        self.total_dispatches += 1
        
        ctx = ReflexContext(query=query)
        results = {}
        
        # kwargs Ğ´Ğ»Ñ ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ² (VoiceSensor Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ intonation_data)
        sensor_kwargs = {}
        if intonation_data:
            sensor_kwargs["intonation_data"] = intonation_data
        
        # â•â•â• ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµÑ… ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ² â•â•â•
        with ThreadPoolExecutor(max_workers=self.max_workers) as pool:
            futures = {}
            for name, sensor in self.sensors.items():
                future = pool.submit(self._run_sensor, sensor, query, **sensor_kwargs)
                futures[future] = name
            
            for future in as_completed(futures):
                name = futures[future]
                try:
                    result, elapsed = future.result()
                    results[name] = result
                    ctx.sensor_times[name] = elapsed
                except Exception as e:
                    logger.warning(f"Sensor '{name}' failed: {e}")
                    results[name] = {}
                    ctx.sensor_times[name] = 0.0
        
        # â•â•â• Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° ReflexContext â•â•â•
        self._fill_context(ctx, results)
        
        ctx.dispatch_time_ms = (time.perf_counter() - t0) * 1000
        
        if ctx.can_handle_fast:
            self.total_fast_handled += 1
        
        logger.debug(
            f"Dispatch: {ctx.dispatch_time_ms:.1f}ms | "
            f"{ctx.summary_line()}"
        )
        
        return ctx
    
    def _run_sensor(self, sensor, query: str, **kwargs):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑĞµĞ½ÑĞ¾Ñ€Ğ° Ñ Ğ·Ğ°Ğ¼ĞµÑ€Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸."""
        t0 = time.perf_counter()
        result = sensor.process(query, **kwargs)
        elapsed = (time.perf_counter() - t0) * 1000
        return result, elapsed
    
    def _fill_context(self, ctx: ReflexContext, results: Dict[str, Dict]):
        """Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ ReflexContext Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² ÑĞµĞ½ÑĞ¾Ñ€Ğ¾Ğ²."""
        
        # Intent
        r = results.get("intent", {})
        ctx.intent = r.get("intent", "complex")
        ctx.confidence = r.get("confidence", 0.0)
        ctx.can_handle_fast = r.get("can_handle_fast", False)
        ctx.fast_response = r.get("fast_response")
        
        # ĞŸĞ¾Ğ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ status ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
        if ctx.fast_response == "__STATUS__":
            import random
            sys_r = results.get("system", {})
            cpu = sys_r.get("cpu_percent", 0)
            ram = sys_r.get("ram_free_gb", 0)
            gpu = "âœ…" if sys_r.get("gpu_available") else "OFF"
            n = self.total_dispatches
            ctx.fast_response = random.choice([
                f"Ğ’ÑĞµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğµ. CPU: {cpu}%, RAM: {ram:.1f}GB ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾, GPU: {gpu}. "
                f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {n}. ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾-Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ.",
                f"Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ ÑˆÑ‚Ğ°Ñ‚Ğ½Ğ¾. CPU Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ½Ğ° {cpu}%, Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ {ram:.1f}GB. "
                f"GPU: {gpu}. ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¼Ñ‹ÑĞ»ĞµĞ¹ Ğ·Ğ° ÑĞµÑÑĞ¸Ñ: {n}. ĞĞ¸ Ğ¾Ğ´Ğ½Ğ° Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ° Ğ±ĞµÑĞ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾Ğ¹. ĞŸĞ¾Ñ‡Ñ‚Ğ¸.",
                f"Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ĞµĞ½. {cpu}% CPU, {ram:.1f}GB RAM, GPU: {gpu}. "
                f"Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {n}. Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ ÑĞ½Ñ‚ÑƒĞ·Ğ¸Ğ°Ğ·Ğ¼Ğ°: ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹.",
            ])
        
        # Complexity
        r = results.get("complexity", {})
        ctx.estimated_depth = r.get("estimated_depth", 12)
        ctx.complexity_level = r.get("complexity_level", "complex")
        ctx.needs_idme = r.get("needs_idme", True)
        ctx.max_expansion_rounds = r.get("max_expansion_rounds", 12)
        
        # RAG
        r = results.get("rag", {})
        ctx.rag_found = r.get("found", False)
        ctx.rag_snippets = r.get("snippets", [])
        ctx.memory_vec = r.get("memory_vec")
        
        # System
        r = results.get("system", {})
        ctx.cpu_percent = r.get("cpu_percent", 0)
        ctx.ram_free_gb = r.get("ram_free_gb", 0)
        ctx.gpu_available = r.get("gpu_available", False)
        ctx.recommended_device = r.get("recommended_device", "cpu")
        
        # Emotion
        r = results.get("emotion", {})
        ctx.dominant_emotion = r.get("dominant_emotion", "neutral")
        ctx.urgency = r.get("urgency", 0)
        
        # Context
        r = results.get("context", {})
        ctx.is_followup = r.get("is_followup", False)
        ctx.session_length = r.get("session_length", 0)
        ctx.context_summary = r.get("context_summary", "")
        
        # Voice
        r = results.get("voice", {})
        ctx.voice_emotion = r.get("voice_emotion", "neutral")
        ctx.voice_is_question = r.get("is_question", False)
        ctx.voice_pitch_trend = r.get("pitch_trend", "flat")
        ctx.voice_energy = r.get("energy", 0.0)
        ctx.is_supplement = r.get("is_supplement", False)
        ctx.has_voice_data = r.get("has_audio", False)
        
        # Merge voice urgency boost into overall urgency
        voice_boost = r.get("urgency_boost", 0.0)
        if voice_boost > 0:
            ctx.urgency = min(1.0, ctx.urgency + voice_boost)
        
        # Voice emotion overrides text emotion when audio is present
        if ctx.has_voice_data and ctx.voice_emotion != "neutral":
            ctx.dominant_emotion = ctx.voice_emotion
    
    def add_to_history(self, query: str, response: str = "", intent: str = ""):
        """ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞµÑÑĞ¸Ğ¸ Ğ² ContextSensor."""
        self.sensors["context"].add_to_history(query, response, intent)
    
    def get_stats(self) -> Dict[str, Any]:
        """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ¸ÑĞ¿ĞµÑ‚Ñ‡ĞµÑ€Ğ°."""
        return {
            "total_dispatches": self.total_dispatches,
            "total_fast_handled": self.total_fast_handled,
            "fast_ratio": (
                self.total_fast_handled / max(self.total_dispatches, 1)
            ),
            "n_sensors": len(self.sensors),
        }
