"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  Self-Learning Module ‚Äî –û–Ω–ª–∞–π–Ω –¥–æ–æ–±—É—á–µ–Ω–∏–µ –¢–ê–†–°
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–¢–ê–†–° —É—á–∏—Ç—Å—è –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º –æ–ø—ã—Ç–µ:
  1. –õ–æ–≥–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —Ü–∏–∫–ª –º—ã—à–ª–µ–Ω–∏—è (ThinkingLogger)
  2. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–∞—ë—Ç feedback (quality 0-1)
  3. Self-learner –Ω–∞—Ö–æ–¥–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã:
     - –ö–∞–∫–∏–µ MoLE —ç–∫—Å–ø–µ—Ä—Ç—ã –ª—É—á—à–µ –¥–ª—è –∫–∞–∫–∏—Ö –∑–∞–¥–∞—á
     - –ö–∞–∫–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –∏–∑ –ø—É–ª–∞ –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã
     - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ p –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
  4. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –¥–æ–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –ª—É—á—à–∏—Ö —Å–µ—Å—Å–∏—è—Ö

–¢—Ä–∏ —Ä–µ–∂–∏–º–∞:
  - Passive: —Ç–æ–ª—å–∫–æ —Å–æ–±–∏—Ä–∞–µ—Ç –ª–æ–≥–∏
  - Active: –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç routing weights
  - Full: gradient update –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –º–æ–¥–µ–ª–∏ (—Ç—Ä–µ–±—É–µ—Ç GPU)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import logging
import os
import json
from typing import Optional, List, Dict
from datetime import datetime


class SelfLearner:
    """
    –ú–æ–¥—É–ª—å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –¢–ê–†–°.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ ThinkingLogger –¥–ª—è:
      - –ö–æ—Ä—Ä–µ–∫—Ü–∏–∏ routing weights –≤ MoLE
      - –û–±–Ω–æ–≤–ª–µ–Ω–∏—è efficiency –≤ MatrixPool
      - –ê–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ—Ä–æ–≥–æ–≤ MetaAuditor
      - (Full mode) Gradient update –Ω–∞ –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, model=None, lr: float = 1e-5, 
                 log_dir: str = "data/thinking_logs"):
        self.model = model
        self.lr = lr
        self.log_dir = log_dir
        self.logger = logging.getLogger("Tars.SelfLearn")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.session_count = 0
        self.positive_sessions = 0
        self.negative_sessions = 0
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (lazy init)
        self._optimizer = None
    
    def record_feedback(self, quality: float):
        """
        –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        quality: 0.0 (–ø–ª–æ—Ö–æ) ‚Üí 1.0 (–æ—Ç–ª–∏—á–Ω–æ)
        """
        self.session_count += 1
        if quality >= 0.7:
            self.positive_sessions += 1
        else:
            self.negative_sessions += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º feedback –≤ –ª–æ–≥
        if self.model and hasattr(self.model, 'thinking_logger'):
            self.model.thinking_logger.record_feedback(quality)
        
        self.logger.info(
            f"SelfLearn: feedback={quality:.2f} "
            f"(pos={self.positive_sessions}, neg={self.negative_sessions})"
        )
    
    def adapt_routing(self):
        """
        Passive learning: –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç MoLE routing –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–æ–≤.
        
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç, –∫–∞–∫–∏–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–ª–∏—Å—å –≤ —Ö–æ—Ä–æ—à–∏—Ö/–ø–ª–æ—Ö–∏—Ö —Å–µ—Å—Å–∏—è—Ö,
        –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç routing weights.
        """
        if self.model is None:
            return
        
        good_sessions = self._load_sessions(min_quality=0.8)
        bad_sessions = self._load_sessions(max_quality=0.4)
        
        if len(good_sessions) < 3:
            self.logger.debug("SelfLearn: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏")
            return
        
        # –ê–Ω–∞–ª–∏–∑ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        good_experts = {}
        bad_experts = {}
        
        for session in good_sessions:
            for step in session.get("steps", []):
                for expert in step.get("experts", []):
                    name = expert.split("(")[0]
                    good_experts[name] = good_experts.get(name, 0) + 1
        
        for session in bad_sessions:
            for step in session.get("steps", []):
                for expert in step.get("experts", []):
                    name = expert.split("(")[0]
                    bad_experts[name] = bad_experts.get(name, 0) + 1
        
        self.logger.info(f"SelfLearn: Good experts: {good_experts}")
        self.logger.info(f"SelfLearn: Bad experts: {bad_experts}")
    
    def adapt_thresholds(self):
        """
        –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø–æ—Ä–æ–≥–∏ p –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
        –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        if self.model is None or not hasattr(self.model, 'meta_auditor'):
            return
        
        sessions = self._load_sessions(min_quality=0.7)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ task_type
        type_stats = {}
        for session in sessions:
            task_type = session.get("task_type", "chat")
            final_p = session.get("final_p", 0)
            converged = session.get("converged", False)
            
            if task_type not in type_stats:
                type_stats[task_type] = {"p_values": [], "converged": 0, "total": 0}
            
            type_stats[task_type]["p_values"].append(final_p)
            type_stats[task_type]["total"] += 1
            if converged:
                type_stats[task_type]["converged"] += 1
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥–∏
        for task_type, stats in type_stats.items():
            if stats["total"] >= 5:
                avg_p = sum(stats["p_values"]) / len(stats["p_values"])
                convergence_rate = stats["converged"] / stats["total"]
                
                # –ï—Å–ª–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å > 90% ‚Üí –ø–æ—Ä–æ–≥ –º–æ–∂–Ω–æ —Å–Ω–∏–∑–∏—Ç—å –Ω–µ–º–Ω–æ–≥–æ
                if convergence_rate > 0.9 and task_type in self.model.meta_auditor.THRESHOLDS:
                    old_threshold = self.model.meta_auditor.THRESHOLDS[task_type]
                    # –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è
                    new_threshold = 0.9 * old_threshold + 0.1 * avg_p
                    self.model.meta_auditor.THRESHOLDS[task_type] = new_threshold
                    
                    self.logger.info(
                        f"SelfLearn: {task_type} threshold: "
                        f"{old_threshold:.2f} ‚Üí {new_threshold:.2f}"
                    )
    
    def fine_tune_step(self, input_ids: torch.Tensor, 
                       labels: torch.Tensor) -> float:
        """
        Full mode: –æ–¥–∏–Ω —à–∞–≥ gradient update.
        
        –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç TarsCoreBlock (SSD+WKV), —É—á–∏—Ç —Ç–æ–ª—å–∫–æ:
          - MoLE routing weights (per block)
          - Œ©-SSM projections (per block)  
          - NoveltyGate (per block)
          - MatrixPool domain embeddings (model-level)
        """
        if self.model is None:
            return 0.0
        
        if self._optimizer is None:
            # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º TarsCoreBlock (SSD + WKV + Fusion)
            for block in self.model.blocks:
                for param in block.core.parameters():
                    param.requires_grad = False
            
            # –£—á–∏–º —Ç–æ–ª—å–∫–æ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –º–æ–¥—É–ª–∏
            trainable = []
            for block in self.model.blocks:
                trainable.extend(block.omega.parameters())
                trainable.extend(block.mole.parameters())
                trainable.extend(block.novelty_gate.parameters())
                trainable.extend(block.rag_query.parameters())
                trainable.extend(block.rag_out.parameters())
                trainable.extend(block.mem_proj.parameters())
            
            # Model-level modules
            if hasattr(self.model, 'matrix_pool'):
                trainable.extend(self.model.matrix_pool.parameters())
            
            self._optimizer = torch.optim.AdamW(
                trainable, lr=self.lr, weight_decay=0.01
            )
        
        self.model.train()
        self._optimizer.zero_grad()
        
        logits, loss = self.model(input_ids, labels=labels)
        loss.backward()
        
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
        self._optimizer.step()
        
        self.model.eval()
        return loss.item()
    
    def sleep_phase(self):
        """
        –§–∞–∑–∞ —Å–Ω–∞: –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π.
        
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞–ø—Ä–∏–º–µ—Ä –∫–∞–∂–¥—ã–µ 50 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –∏–ª–∏ –ø–æ —Ç–∞–π–º–µ—Ä—É.
        """
        self.logger.info("SelfLearn: üí§ –§–∞–∑–∞ —Å–Ω–∞ ‚Äî –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π...")
        
        # 1. –ê–¥–∞–ø—Ç–∞—Ü–∏—è routing
        self.adapt_routing()
        
        # 2. –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ—Ä–æ–≥–æ–≤
        self.adapt_thresholds()
        
        # 3. Full fine-tune –Ω–∞ –ª—É—á—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å GPU)
        good_sessions = self._load_sessions(min_quality=0.8)
        if len(good_sessions) >= 10 and self.model is not None:
            device = next(self.model.parameters()).device
            if device.type == 'cuda':
                self.logger.info(
                    f"SelfLearn: Fine-tune –Ω–∞ {len(good_sessions)} —Å–µ—Å—Å–∏—è—Ö..."
                )
                total_loss = 0.0
                n_steps = 0
                for session in good_sessions[-20:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Ö–æ—Ä–æ—à–∏—Ö
                    input_text = session.get("input", "")
                    response_text = session.get("response", "")
                    if not input_text or not response_text:
                        continue
                    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ cp1251 byte-level
                    combined = f"{input_text}\n{response_text}"
                    tokens = list(combined.encode('cp1251', errors='replace'))
                    if len(tokens) < 8:
                        continue
                    token_tensor = torch.tensor(tokens, dtype=torch.long, device=device)
                    input_ids = token_tensor[:-1].unsqueeze(0)
                    labels = token_tensor[1:].unsqueeze(0)
                    loss = self.fine_tune_step(input_ids, labels)
                    total_loss += loss
                    n_steps += 1
                if n_steps > 0:
                    self.logger.info(
                        f"SelfLearn: Fine-tune done: {n_steps} steps, "
                        f"avg_loss={total_loss / n_steps:.4f}"
                    )
        
        # 4. Synaptic Homeostasis (Tononi, 2003)
        # –ù–µ–π—Ä–æ–Ω–∞—É–∫–∞: –≤–æ –≤—Ä–µ–º—è –±–æ–¥—Ä—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–∏–Ω–∞–ø—Å—ã —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è (LTP).
        # –í–æ –≤—Ä–µ–º—è —Å–Ω–∞ ‚Äî –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –æ—Å–ª–∞–±–ª–µ–Ω–∏–µ (downscaling), —Å–æ—Ö—Ä–∞–Ω—è—é—â–µ–µ
        # –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏. –≠—Ç–æ —É–ª—É—á—à–∞–µ—Ç SNR –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã.
        self._synaptic_downscaling()
        
        # 5. Hippocampal Replay (–≥–∏–ø–ø–æ–∫–∞–º–ø–∞–ª—å–Ω—ã–π —Ä–µ–ø–ª–µ–π)
        # –ù–µ–π—Ä–æ–Ω–∞—É–∫–∞: –≥–∏–ø–ø–æ–∫–∞–º–ø –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ—Ç –¥–Ω–µ–≤–Ω–æ–π –æ–ø—ã—Ç –≤–æ —Å–Ω–µ
        # –≤ 5-20√ó —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–º —Ç–µ–º–ø–µ (sharp-wave ripples),
        # –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É—è —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–µ/–≤–∞–∂–Ω—ã–µ —ç–ø–∏–∑–æ–¥—ã.
        self._hippocampal_replay()
        
        self.logger.info("SelfLearn: üí§ –§–∞–∑–∞ —Å–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def _hippocampal_replay(self, n_replays: int = 15, compression: int = 5):
        """
        Hippocampal Replay (Wilson & McNaughton, 1994).
        
        –ù–µ–π—Ä–æ–Ω–∞—É–∫–∞: –≤–æ —Å–Ω–µ –≥–∏–ø–ø–æ–∫–∞–º–ø –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ—Ç —ç–ø–∏–∑–æ–¥—ã –¥–Ω—è
        –≤ 5-20√ó —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–º —Ç–µ–º–ø–µ. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —ç–ø–∏–∑–æ–¥—ã
        (—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–µ, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ) –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—è—Ç—Å—è —á–∞—â–µ.
        
        –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ (Prioritized Experience Replay):
          P(i) = p_i^Œ± / Œ£_k p_k^Œ±       # priority sampling
          p_i = surprise_i * recency_i     # priority = surprise √ó recency
          tokens_replay = tokens[::compression]  # temporal compression
        """
        if self.model is None:
            return
        
        device = next(self.model.parameters()).device
        if device.type != 'cuda':
            return  # Only on GPU
        
        all_sessions = self._load_sessions(min_quality=0.0)
        if len(all_sessions) < 5:
            return
        
        # Compute priorities: surprise √ó recency
        import numpy as np
        priorities = []
        for i, s in enumerate(all_sessions):
            surprise = s.get("quality", 0.5)  # quality as proxy for importance
            recency = 1.0 / (len(all_sessions) - i + 1)
            priorities.append((surprise + 0.1) * recency)
        
        # Normalize to probability distribution
        priorities = np.array(priorities)
        probs = priorities / (priorities.sum() + 1e-8)
        
        # Sample sessions proportionally to priority
        n_replay = min(n_replays, len(all_sessions))
        indices = np.random.choice(len(all_sessions), size=n_replay, p=probs, replace=False)
        
        total_loss = 0.0
        replayed = 0
        
        for idx in indices:
            session = all_sessions[idx]
            input_text = session.get("input", "")
            response_text = session.get("response", "")
            if not input_text or not response_text:
                continue
            
            combined = f"{input_text}\n{response_text}"
            tokens = list(combined.encode('cp1251', errors='replace'))
            
            # Temporal compression: skip every N-th token (5√ó faster)
            tokens = tokens[::compression]
            
            if len(tokens) < 4:
                continue
            
            token_tensor = torch.tensor(tokens, dtype=torch.long, device=device)
            input_ids = token_tensor[:-1].unsqueeze(0)
            labels = token_tensor[1:].unsqueeze(0)
            
            loss = self.fine_tune_step(input_ids, labels)
            total_loss += loss
            replayed += 1
        
        if replayed > 0:
            self.logger.info(
                f"SelfLearn: üåô Hippocampal replay: {replayed} episodes "
                f"(√ó{compression} compression), avg_loss={total_loss / replayed:.4f}"
            )
    
    def _synaptic_downscaling(self, factor: float = 0.92):
        """
        Synaptic Homeostasis (Tononi, 2003).
        
        –í–æ –≤—Ä–µ–º—è –±–æ–¥—Ä—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–∏–Ω–∞–ø—Å—ã —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è (LTP/fine-tune).
        –í–æ –≤—Ä–µ–º—è —Å–Ω–∞ ‚Äî –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –æ—Å–ª–∞–±–ª–µ–Ω–∏–µ:
          w_sleep = w_wake √ó Œª,  Œª ‚àà (0.8, 0.95)
        
        –°–≤–æ–π—Å—Ç–≤–∞:
          - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç w‚ÇÅ/w‚ÇÇ = const (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –≤–∞–∂–Ω–æ—Å—Ç—å)
          - –£–º–µ–Ω—å—à–∞–µ—Ç ||w|| (—ç–Ω–µ—Ä–≥–æ–∑–∞—Ç—Ä–∞—Ç—ã, saturation risk)
          - –£–ª—É—á—à–∞–µ—Ç SNR (signal-to-noise ratio)
        
        –¢—Ä–æ–≥–∞–µ–º –¢–û–õ–¨–ö–û –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (MoLE, Œ©-SSM, NoveltyGate,
        Memory projections), –ù–ï —Ç—Ä–æ–≥–∞–µ–º core SSD/WKV ‚Äî –æ–Ω–∏ –æ–±—É—á–µ–Ω—ã –∑–∞
        –¥–æ—Ä–æ–≥—É—é —Ñ–∞–∑—É full pretrain.
        """
        if self.model is None:
            return
        
        downscaled = 0
        with torch.no_grad():
            for block in self.model.blocks:
                # MoLE expert LoRA weights (—Å–∞–º—ã–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ)
                if hasattr(block, 'mole'):
                    for expert in block.mole.experts:
                        if hasattr(expert, 'A'):
                            expert.A.weight.data *= factor
                        if hasattr(expert, 'B'):
                            expert.B.weight.data *= factor
                        downscaled += 1
                
                # Œ©-SSM projections (Lie algebra)
                if hasattr(block, 'omega'):
                    if hasattr(block.omega, 'omega_proj'):
                        block.omega.omega_proj.weight.data *= factor
                    if hasattr(block.omega, 'omega_mix'):
                        block.omega.omega_mix.data *= factor
                    downscaled += 1
                
                # NoveltyGate
                if hasattr(block, 'novelty_gate'):
                    for p in block.novelty_gate.parameters():
                        p.data *= factor
                    downscaled += 1
                
                # Memory injection gates
                if hasattr(block, 'mem_gate'):
                    for p in block.mem_gate.parameters():
                        p.data *= factor
                    downscaled += 1
            
            # MatrixPool efficiency scores (recirculation)
            if hasattr(self.model, 'matrix_pool'):
                self.model.matrix_pool.efficiency *= factor
                downscaled += 1
        
        self.logger.info(
            f"SelfLearn: üß¨ Synaptic downscaling (Œª={factor}): "
            f"{downscaled} components renormalized"
        )
    
    def _load_sessions(self, min_quality: float = 0.0, 
                       max_quality: float = 1.0) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ—Å—Å–∏–π –∏–∑ –ª–æ–≥–æ–≤."""
        sessions = []
        try:
            for fname in os.listdir(self.log_dir):
                if not fname.endswith('.json'):
                    continue
                filepath = os.path.join(self.log_dir, fname)
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                quality = data.get("response_quality")
                if quality is not None:
                    if min_quality <= quality <= max_quality:
                        sessions.append(data)
        except Exception:
            pass
        return sessions
    
    def save_checkpoint(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏."""
        if self.model is None:
            return
        
        os.makedirs(os.path.dirname(path), exist_ok=True)
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'd_model': self.model.d_model,
            'n_layers': self.model.n_layers,
            'vocab_size': self.model.vocab_size,
            'session_count': self.session_count,
            'positive_sessions': self.positive_sessions,
            'timestamp': datetime.now().isoformat(),
        }, path)
        self.logger.info(f"SelfLearn: Checkpoint saved to {path}")
