"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  Self-Learning Module ‚Äî –û–Ω–ª–∞–π–Ω –¥–æ–æ–±—É—á–µ–Ω–∏–µ –¢–ê–†–°
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–¢–ê–†–° —É—á–∏—Ç—Å—è –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º –æ–ø—ã—Ç–µ:
  1. –õ–æ–≥–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —Ü–∏–∫–ª –º—ã—à–ª–µ–Ω–∏—è (ThinkingLogger)
  2. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–∞—ë—Ç feedback (quality 0-1)
  3. Self-learner –Ω–∞—Ö–æ–¥–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã:
     - –ö–∞–∫–∏–µ MoLE —ç–∫—Å–ø–µ—Ä—Ç—ã –ª—É—á—à–µ –¥–ª—è –∫–∞–∫–∏—Ö –∑–∞–¥–∞—á
     - –ö–∞–∫–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –∏–∑ –ø—É–ª–∞ –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã
     - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ p –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
  4. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –¥–æ–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –ª—É—á—à–∏—Ö —Å–µ—Å—Å–∏—è—Ö

–¢—Ä–∏ —Ä–µ–∂–∏–º–∞:
  - Passive: —Ç–æ–ª—å–∫–æ —Å–æ–±–∏—Ä–∞–µ—Ç –ª–æ–≥–∏
  - Active: –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç routing weights
  - Full: gradient update –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –º–æ–¥–µ–ª–∏ (—Ç—Ä–µ–±—É–µ—Ç GPU)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import logging
import os
import json
from typing import Optional, List, Dict
from datetime import datetime


class SelfLearner:
    """
    –ú–æ–¥—É–ª—å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –¢–ê–†–°.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ ThinkingLogger –¥–ª—è:
      - –ö–æ—Ä—Ä–µ–∫—Ü–∏–∏ routing weights –≤ MoLE
      - –û–±–Ω–æ–≤–ª–µ–Ω–∏—è efficiency –≤ MatrixPool
      - –ê–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ—Ä–æ–≥–æ–≤ MetaAuditor
      - (Full mode) Gradient update –Ω–∞ –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, model=None, lr: float = 1e-5, 
                 log_dir: str = "data/thinking_logs"):
        self.model = model
        self.lr = lr
        self.log_dir = log_dir
        self.logger = logging.getLogger("Tars.SelfLearn")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.session_count = 0
        self.positive_sessions = 0
        self.negative_sessions = 0
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (lazy init)
        self._optimizer = None
    
    def record_feedback(self, quality: float):
        """
        –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        quality: 0.0 (–ø–ª–æ—Ö–æ) ‚Üí 1.0 (–æ—Ç–ª–∏—á–Ω–æ)
        """
        self.session_count += 1
        if quality >= 0.7:
            self.positive_sessions += 1
        else:
            self.negative_sessions += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º feedback –≤ –ª–æ–≥
        if self.model and hasattr(self.model, 'thinking_logger'):
            self.model.thinking_logger.record_feedback(quality)
        
        self.logger.info(
            f"SelfLearn: feedback={quality:.2f} "
            f"(pos={self.positive_sessions}, neg={self.negative_sessions})"
        )
    
    def adapt_routing(self):
        """
        Passive learning: –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç MoLE routing –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–æ–≤.
        
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç, –∫–∞–∫–∏–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–ª–∏—Å—å –≤ —Ö–æ—Ä–æ—à–∏—Ö/–ø–ª–æ—Ö–∏—Ö —Å–µ—Å—Å–∏—è—Ö,
        –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç routing weights.
        """
        if self.model is None:
            return
        
        good_sessions = self._load_sessions(min_quality=0.8)
        bad_sessions = self._load_sessions(max_quality=0.4)
        
        if len(good_sessions) < 3:
            self.logger.debug("SelfLearn: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏")
            return
        
        # –ê–Ω–∞–ª–∏–∑ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        good_experts = {}
        bad_experts = {}
        
        for session in good_sessions:
            for step in session.get("steps", []):
                for expert in step.get("experts", []):
                    name = expert.split("(")[0]
                    good_experts[name] = good_experts.get(name, 0) + 1
        
        for session in bad_sessions:
            for step in session.get("steps", []):
                for expert in step.get("experts", []):
                    name = expert.split("(")[0]
                    bad_experts[name] = bad_experts.get(name, 0) + 1
        
        self.logger.info(f"SelfLearn: Good experts: {good_experts}")
        self.logger.info(f"SelfLearn: Bad experts: {bad_experts}")
    
    def adapt_thresholds(self):
        """
        –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø–æ—Ä–æ–≥–∏ p –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
        –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        if self.model is None or not hasattr(self.model, 'meta_auditor'):
            return
        
        sessions = self._load_sessions(min_quality=0.7)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ task_type
        type_stats = {}
        for session in sessions:
            task_type = session.get("task_type", "chat")
            final_p = session.get("final_p", 0)
            converged = session.get("converged", False)
            
            if task_type not in type_stats:
                type_stats[task_type] = {"p_values": [], "converged": 0, "total": 0}
            
            type_stats[task_type]["p_values"].append(final_p)
            type_stats[task_type]["total"] += 1
            if converged:
                type_stats[task_type]["converged"] += 1
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥–∏
        for task_type, stats in type_stats.items():
            if stats["total"] >= 5:
                avg_p = sum(stats["p_values"]) / len(stats["p_values"])
                convergence_rate = stats["converged"] / stats["total"]
                
                # –ï—Å–ª–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å > 90% ‚Üí –ø–æ—Ä–æ–≥ –º–æ–∂–Ω–æ —Å–Ω–∏–∑–∏—Ç—å –Ω–µ–º–Ω–æ–≥–æ
                if convergence_rate > 0.9 and task_type in self.model.meta_auditor.THRESHOLDS:
                    old_threshold = self.model.meta_auditor.THRESHOLDS[task_type]
                    # –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è
                    new_threshold = 0.9 * old_threshold + 0.1 * avg_p
                    self.model.meta_auditor.THRESHOLDS[task_type] = new_threshold
                    
                    self.logger.info(
                        f"SelfLearn: {task_type} threshold: "
                        f"{old_threshold:.2f} ‚Üí {new_threshold:.2f}"
                    )
    
    def fine_tune_step(self, input_ids: torch.Tensor, 
                       labels: torch.Tensor) -> float:
        """
        Full mode: –æ–¥–∏–Ω —à–∞–≥ gradient update.
        
        –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç TarsCoreBlock (SSD+WKV), —É—á–∏—Ç —Ç–æ–ª—å–∫–æ:
          - MoLE routing weights (per block)
          - Œ©-SSM projections (per block)  
          - NoveltyGate (per block)
          - MatrixPool domain embeddings (model-level)
        """
        if self.model is None:
            return 0.0
        
        if self._optimizer is None:
            # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º TarsCoreBlock (SSD + WKV + Fusion)
            for block in self.model.blocks:
                for param in block.core.parameters():
                    param.requires_grad = False
            
            # –£—á–∏–º —Ç–æ–ª—å–∫–æ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –º–æ–¥—É–ª–∏
            trainable = []
            for block in self.model.blocks:
                trainable.extend(block.omega.parameters())
                trainable.extend(block.mole.parameters())
                trainable.extend(block.novelty_gate.parameters())
                trainable.extend(block.rag_query.parameters())
                trainable.extend(block.rag_out.parameters())
                trainable.extend(block.mem_proj.parameters())
            
            # Model-level modules
            if hasattr(self.model, 'matrix_pool'):
                trainable.extend(self.model.matrix_pool.parameters())
            
            self._optimizer = torch.optim.AdamW(
                trainable, lr=self.lr, weight_decay=0.01
            )
        
        self.model.train()
        self._optimizer.zero_grad()
        
        logits, loss = self.model(input_ids, labels=labels)
        loss.backward()
        
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
        self._optimizer.step()
        
        self.model.eval()
        return loss.item()
    
    def sleep_phase(self):
        """
        –§–∞–∑–∞ —Å–Ω–∞: –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π.
        
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞–ø—Ä–∏–º–µ—Ä –∫–∞–∂–¥—ã–µ 50 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –∏–ª–∏ –ø–æ —Ç–∞–π–º–µ—Ä—É.
        """
        self.logger.info("SelfLearn: üí§ –§–∞–∑–∞ —Å–Ω–∞ ‚Äî –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π...")
        
        # 1. –ê–¥–∞–ø—Ç–∞—Ü–∏—è routing
        self.adapt_routing()
        
        # 2. –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ—Ä–æ–≥–æ–≤
        self.adapt_thresholds()
        
        # 3. Full fine-tune –Ω–∞ –ª—É—á—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å GPU)
        good_sessions = self._load_sessions(min_quality=0.8)
        if len(good_sessions) >= 10 and self.model is not None:
            device = next(self.model.parameters()).device
            if device.type == 'cuda':
                self.logger.info(
                    f"SelfLearn: Fine-tune –Ω–∞ {len(good_sessions)} —Å–µ—Å—Å–∏—è—Ö..."
                )
                # TODO: –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å–µ—Å—Å–∏–π –∏ fine-tune
        
        self.logger.info("SelfLearn: üí§ –§–∞–∑–∞ —Å–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def _load_sessions(self, min_quality: float = 0.0, 
                       max_quality: float = 1.0) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ—Å—Å–∏–π –∏–∑ –ª–æ–≥–æ–≤."""
        sessions = []
        try:
            for fname in os.listdir(self.log_dir):
                if not fname.endswith('.json'):
                    continue
                filepath = os.path.join(self.log_dir, fname)
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                quality = data.get("response_quality")
                if quality is not None:
                    if min_quality <= quality <= max_quality:
                        sessions.append(data)
        except Exception:
            pass
        return sessions
    
    def save_checkpoint(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏."""
        if self.model is None:
            return
        
        os.makedirs(os.path.dirname(path), exist_ok=True)
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'd_model': self.model.d_model,
            'n_layers': self.model.n_layers,
            'vocab_size': self.model.vocab_size,
            'session_count': self.session_count,
            'positive_sessions': self.positive_sessions,
            'timestamp': datetime.now().isoformat(),
        }, path)
        self.logger.info(f"SelfLearn: Checkpoint saved to {path}")
