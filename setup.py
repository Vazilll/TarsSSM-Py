"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Ğ¢ĞĞ Ğ¡ â€” ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ½Ğ° Ğ½Ğ¾Ğ²Ğ¾Ğ¼ ĞŸĞš
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ĞĞ´Ğ¸Ğ½ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´ĞµĞ»Ğ°ĞµÑ‚ Ğ’Ğ¡Ğ:
  1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ (venv)
  2. Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²ÑĞµ Python-Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
  3. Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Whisper, Silero VAD, SentenceTransformer)
  4. Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ (Wikipedia 100K, HuggingFace Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñ‹)
  5. Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ² LEANN (Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ)
  6. ĞĞ±ÑƒÑ‡Ğ°ĞµÑ‚ Ğ²ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Reflex â†’ MinGRU â†’ Mamba-2 Brain)
  7. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
  python setup.py              # ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° + Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
  python setup.py --skip-data  # Ğ‘ĞµĞ· ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ°Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
  python setup.py --skip-train # Ğ‘ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
  python setup.py --gpu        # Ğ¡ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ CUDA GPU
"""

import os
import sys
import subprocess
import shutil
import time
import argparse
import json
import urllib.request
from pathlib import Path

ROOT = Path(__file__).parent
VENV_DIR = ROOT / "venv"
PYTHON = str(VENV_DIR / "Scripts" / "python.exe") if sys.platform == "win32" else str(VENV_DIR / "bin" / "python")
PIP = str(VENV_DIR / "Scripts" / "pip.exe") if sys.platform == "win32" else str(VENV_DIR / "bin" / "pip")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¦Ğ²ĞµÑ‚Ğ° Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def banner(text):
    print(f"\n{'â•' * 60}")
    print(f"  {text}")
    print(f"{'â•' * 60}\n")

def phase(num, total, text):
    print(f"\n{'â”' * 60}")
    print(f"  [{num}/{total}] {text}")
    print(f"{'â”' * 60}")

def ok(text):
    print(f"  âœ… {text}")

def warn(text):
    print(f"  âš ï¸  {text}")

def fail(text):
    print(f"  âŒ {text}")

def info(text):
    print(f"  â„¹  {text}")

def run_cmd(cmd, desc="", check=True, capture=False):
    """Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼."""
    if desc:
        info(desc)
    try:
        result = subprocess.run(
            cmd, shell=isinstance(cmd, str),
            capture_output=capture, text=True,
            check=check
        )
        return result
    except subprocess.CalledProcessError as e:
        if capture:
            warn(f"ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ²ĞµÑ€Ğ½ÑƒĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ: {e.stderr[:200] if e.stderr else ''}")
        return e
    except FileNotFoundError:
        warn(f"ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {cmd[0] if isinstance(cmd, list) else cmd}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¤Ğ°Ğ·Ğ° 1: Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def setup_venv():
    phase(1, 7, "ğŸ Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Python")
    
    if VENV_DIR.exists() and Path(PYTHON).exists():
        ok(f"venv ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚: {VENV_DIR}")
        return True
    
    info("Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ...")
    result = run_cmd([sys.executable, "-m", "venv", str(VENV_DIR)], check=False)
    if result and not isinstance(result, Exception):
        ok("venv ÑĞ¾Ğ·Ğ´Ğ°Ğ½")
        return True
    else:
        fail("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ venv")
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¤Ğ°Ğ·Ğ° 2: Python-Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def install_dependencies(use_gpu=False):
    phase(2, 7, "ğŸ“¦ Python-Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸")
    
    python = PYTHON if Path(PYTHON).exists() else sys.executable
    pip = PIP if Path(PIP).exists() else f"{python} -m pip"
    
    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ pip
    run_cmd(f"{python} -m pip install --upgrade pip", "ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ pip...", check=False)
    
    # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    core_deps = [
        "numpy", "einops", "tqdm", "sentencepiece", "tokenizers",
    ]
    
    # PyTorch (Ñ CUDA ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶ĞµĞ½)
    if use_gpu:
        info("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° PyTorch Ñ CUDA...")
        run_cmd(
            f"{python} -m pip install torch --index-url https://download.pytorch.org/whl/cu121",
            check=False
        )
    else:
        core_deps.append("torch")
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ core
    for dep in core_deps:
        run_cmd(f"{python} -m pip install {dep}", f"Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° {dep}...", check=False)
    
    # Ğ“Ğ¾Ğ»Ğ¾Ñ (STT/TTS)
    voice_deps = ["faster-whisper", "sounddevice"]
    for dep in voice_deps:
        run_cmd(f"{python} -m pip install {dep}", f"Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° {dep}...", check=False)
    
    # RAG Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
    ml_deps = ["sentence-transformers", "datasets"]
    for dep in ml_deps:
        run_cmd(f"{python} -m pip install {dep}", f"Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° {dep}...", check=False)
    
    # ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾
    optional = ["onnxruntime", "pyttsx3"]
    for dep in optional:
        run_cmd(f"{python} -m pip install {dep}", f"Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° {dep} (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)...", check=False)
    
    ok("Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹")
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¤Ğ°Ğ·Ğ° 3: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_directories():
    phase(3, 7, "ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹")
    
    dirs = [
        ROOT / "data",
        ROOT / "data" / "thinking_logs",
        ROOT / "models",
        ROOT / "models" / "voice",
        ROOT / "models" / "embeddings",
        ROOT / "models" / "brain",
        ROOT / "models" / "mamba2",
        ROOT / "models" / "reflex",
        ROOT / "memory",
    ]
    
    for d in dirs:
        d.mkdir(parents=True, exist_ok=True)
    
    ok(f"Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ {len(dirs)} Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹")
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¤Ğ°Ğ·Ğ° 4: ĞœĞ¾Ğ´ĞµĞ»Ğ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def download_models():
    phase(4, 7, "ğŸ¤– Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹")
    
    python = PYTHON if Path(PYTHON).exists() else sys.executable
    
    # â”€â”€ 1. SentenceTransformer (Ğ´Ğ»Ñ LEANN) â”€â”€
    emb_dir = ROOT / "models" / "embeddings"
    if not (emb_dir / "config.json").exists():
        info("Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ SentenceTransformer (all-MiniLM-L6-v2)...")
        try:
            result = run_cmd(
                f'{python} -c "from sentence_transformers import SentenceTransformer; '
                f"m = SentenceTransformer('all-MiniLM-L6-v2'); "
                f"m.save('{str(emb_dir)}')" + '"',
                check=False
            )
            if (emb_dir / "config.json").exists():
                ok("SentenceTransformer ÑĞºĞ°Ñ‡Ğ°Ğ½ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½")
            else:
                warn("SentenceTransformer: Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ (Ğ±ÑƒĞ´ĞµÑ‚ ÑĞºĞ°Ñ‡Ğ°Ğ½ Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ)")
        except Exception as e:
            warn(f"SentenceTransformer: {e}")
    else:
        ok("SentenceTransformer ÑƒĞ¶Ğµ Ğ½Ğ° Ğ¼ĞµÑÑ‚Ğµ")
    
    # â”€â”€ 2. Whisper Tiny (STT) â”€â”€
    whisper_dir = ROOT / "models" / "voice" / "whisper_tiny"
    if not (whisper_dir / "model.bin").exists():
        info("Whisper Tiny Ğ±ÑƒĞ´ĞµÑ‚ ÑĞºĞ°Ñ‡Ğ°Ğ½ Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ (faster-whisper)")
        info("  Ğ˜Ğ»Ğ¸: python -c \"from faster_whisper import WhisperModel; WhisperModel('tiny')\"")
    else:
        ok("Whisper Tiny ÑƒĞ¶Ğµ Ğ½Ğ° Ğ¼ĞµÑÑ‚Ğµ")
    
    # â”€â”€ 3. Silero VAD (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾) â”€â”€
    vad_path = ROOT / "models" / "voice" / "silero_vad.onnx"
    if not vad_path.exists():
        info("Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Silero VAD (ONNX, ~2MB)...")
        vad_url = "https://models.silero.ai/models/en/vad_v5.onnx"
        try:
            req = urllib.request.Request(vad_url, headers={"User-Agent": "TARS-Setup/1.0"})
            with urllib.request.urlopen(req, timeout=30) as resp:
                with open(str(vad_path), 'wb') as f:
                    f.write(resp.read())
            ok(f"Silero VAD ÑĞºĞ°Ñ‡Ğ°Ğ½ ({vad_path.stat().st_size / 1024:.0f} KB)")
        except Exception as e:
            warn(f"Silero VAD: {e} (ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ±ÑƒĞ´ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ energy-based VAD)")
    else:
        ok("Silero VAD ÑƒĞ¶Ğµ Ğ½Ğ° Ğ¼ĞµÑÑ‚Ğµ")
    
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¤Ğ°Ğ·Ğ° 5: Ğ‘Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def download_knowledge():
    phase(5, 7, "ğŸ“š Ğ‘Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ (Wikipedia + HuggingFace + LEANN)")
    
    python = PYTHON if Path(PYTHON).exists() else sys.executable
    
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ½Ğ°Ñˆ download_all.py
    download_script = ROOT / "training" / "download_all.py"
    if download_script.exists():
        info("Ğ—Ğ°Ğ¿ÑƒÑĞº training/download_all.py...")
        run_cmd(f"{python} {download_script}", check=False)
    else:
        warn("training/download_all.py Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!")
    
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¤Ğ°Ğ·Ğ° 6: ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def train_models(use_gpu=False):
    phase(6, 7, "Training: FP16 init -> 1.58-bit -> train on data")
    
    python = PYTHON if Path(PYTHON).exists() else sys.executable
    train_script = ROOT / "training" / "train_all.py"
    
    if not train_script.exists():
        warn("training/train_all.py Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!")
        return False
    
    # ĞĞ²Ñ‚Ğ¾-Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ CUDA
    device = "auto"  # train_all.py ÑĞ°Ğ¼ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ cuda/cpu
    
    # ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ (ÑÑ€Ğ°Ğ·Ñƒ 1.58-bit, Ğ±ĞµĞ· FP16 ÑÑ‚Ğ°Ğ´Ğ¸Ğ¸):
    #   Phase 1: Reflex Classifier (~30 ÑĞµĞº)
    #   Phase 2: MinGRU (~5 Ğ¼Ğ¸Ğ½)
    #   Phase 3: Mamba-2 + RWKV-7 1.58-bit (~30 Ğ¼Ğ¸Ğ½+ GPU)
    #   Phase 4: Whisper Vocabulary Boost (~1 Ğ¼Ğ¸Ğ½)
    info("CUDA Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸")
    info("  Phase 1: Reflex Classifier (~30 ÑĞµĞº)")
    info("  Phase 2: MinGRU Language Model (~5 Ğ¼Ğ¸Ğ½)")
    info("  Phase 3: Mamba-2 1.58-bit Ğ½Ğ° WIKI+HF Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (~30 Ğ¼Ğ¸Ğ½+ GPU)")
    info("  Phase 4: Whisper Vocabulary Boost (~1 Ğ¼Ğ¸Ğ½)")
    print()
    
    args = ["--device", device]
    run_cmd(
        [python, str(train_script)] + args,
        check=False
    )
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ÑĞ²Ğ¸Ğ»Ğ¸ÑÑŒ (Ğ¿ÑƒÑ‚Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ÑÑ‚ Ñ train_*.py)
    brain_model = ROOT / "models" / "mamba2" / "mamba2_omega.pt"
    brain_158 = ROOT / "models" / "mamba2" / "mamba2_omega_158bit.pt"
    reflex_model = ROOT / "models" / "reflex" / "reflex_classifier.pt"
    mingru_model = ROOT / "models" / "mingru_weights.pt"
    whisper_ctx = ROOT / "models" / "voice" / "whisper_context.json"
    
    trained = []
    if brain_model.exists():
        ok(f"Mamba-2 Brain: {brain_model.stat().st_size / (1024*1024):.1f} MB")
        trained.append("brain")
    if brain_158.exists():
        ok(f"Mamba-2 Brain 1.58-bit: {brain_158.stat().st_size / (1024*1024):.1f} MB")
        trained.append("brain-158bit")
    if reflex_model.exists():
        ok(f"Reflex Classifier: {reflex_model.stat().st_size / 1024:.0f} KB")
        trained.append("reflex")
    if mingru_model.exists():
        ok(f"MinGRU: {mingru_model.stat().st_size / (1024*1024):.1f} MB")
        trained.append("mingru")
    if whisper_ctx.exists():
        ok("Whisper Vocabulary Boost")
        trained.append("whisper")
    
    if not trained:
        warn("ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ²Ñ‹ÑˆĞµ.")
        return False
    
    ok(f"ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¾ {len(trained)} Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: {', '.join(trained)}")
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ¤Ğ°Ğ·Ğ° 7: Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def verify_system():
    phase(7, 7, "ğŸ” Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°")
    
    python = PYTHON if Path(PYTHON).exists() else sys.executable
    checks = []
    
    # 1. Python Ğ¸ torch
    result = run_cmd(
        f'{python} -c "import torch; print(f\'PyTorch {{torch.__version__}}, CUDA: {{torch.cuda.is_available()}}\')"',
        capture=True, check=False
    )
    if result and hasattr(result, 'stdout') and result.stdout:
        ok(f"PyTorch: {result.stdout.strip()}")
        checks.append(True)
    else:
        fail("PyTorch Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")
        checks.append(False)
    
    # 2. einops
    result = run_cmd(f'{python} -c "import einops; print(\'OK\')"', capture=True, check=False)
    checks.append(result and hasattr(result, 'stdout') and 'OK' in (result.stdout or ''))
    if checks[-1]:
        ok("einops")
    else:
        fail("einops Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")
    
    # 3. Brain modules
    result = run_cmd(
        f'{python} -c "from brain.mamba2.model import TarsMamba2LM; print(\'OK\')"',
        capture=True, check=False
    )
    if result and hasattr(result, 'stdout') and 'OK' in (result.stdout or ''):
        ok("Brain (TarsMamba2LM)")
        checks.append(True)
    else:
        warn("Brain: Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° (Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½ÑƒĞ¶Ğ½Ñ‹ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)")
        checks.append(False)
    
    # 4. Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ
    wiki_path = ROOT / "data" / "wiki_ru.txt"
    if wiki_path.exists():
        size_mb = wiki_path.stat().st_size / (1024 * 1024)
        ok(f"Wikipedia: {size_mb:.1f} MB")
        checks.append(True)
    else:
        warn("Wikipedia: Ğ½Ğµ ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ° (Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ python training/download_all.py)")
        checks.append(False)
    
    # 5. LEANN Ğ¸Ğ½Ğ´ĞµĞºÑ
    leann_path = ROOT / "memory" / "leann.index"
    if leann_path.exists():
        size_mb = leann_path.stat().st_size / (1024 * 1024)
        try:
            with open(leann_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            docs = len(data.get("texts", []))
            ok(f"LEANN: {docs} Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², {size_mb:.1f} MB")
        except Exception:
            ok(f"LEANN: {size_mb:.1f} MB")
        checks.append(True)
    else:
        warn("LEANN: Ğ¿ÑƒÑÑ‚ (Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ Ğ¿Ñ€Ğ¸ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)")
        checks.append(False)
    
    # 6. HF Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    hf_files = list((ROOT / "data").glob("hf_*.txt")) if (ROOT / "data").exists() else []
    if hf_files:
        total_mb = sum(f.stat().st_size for f in hf_files) / (1024 * 1024)
        ok(f"HuggingFace: {len(hf_files)} Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ², {total_mb:.1f} MB")
        checks.append(True)
    else:
        warn("HuggingFace: Ğ½Ğµ ÑĞºĞ°Ñ‡Ğ°Ğ½Ñ‹")
        checks.append(False)
    
    # 7. ĞœĞ¾Ğ´ĞµĞ»Ğ¸
    emb_ok = (ROOT / "models" / "embeddings" / "config.json").exists()
    vad_ok = (ROOT / "models" / "voice" / "silero_vad.onnx").exists()
    if emb_ok:
        ok("SentenceTransformer (embeddings)")
    else:
        warn("SentenceTransformer: Ğ½Ğµ ÑĞºĞ°Ñ‡Ğ°Ğ½")
    if vad_ok:
        ok("Silero VAD (ONNX)")
    else:
        warn("Silero VAD: Ğ½Ğµ ÑĞºĞ°Ñ‡Ğ°Ğ½")
    
    # Ğ˜Ñ‚Ğ¾Ğ³
    passed = sum(1 for c in checks if c)
    total = len(checks)
    print()
    if passed == total:
        banner("âœ… Ğ¢ĞĞ Ğ¡ ĞŸĞĞ›ĞĞĞ¡Ğ¢Ğ¬Ğ® Ğ“ĞĞ¢ĞĞ’ Ğš Ğ ĞĞ‘ĞĞ¢Ğ•")
    else:
        banner(f"âš ï¸  Ğ¢ĞĞ Ğ¡ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ² ({passed}/{total} Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¾Ğº)")
    
    print(f"  Ğ—Ğ°Ğ¿ÑƒÑĞº:      python launch_tars.py")
    print(f"  ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ:    python training/train_mamba2.py --phase 1")
    print(f"  Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ:      python training/download_all.py")
    print()
    
    return all(checks)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="Ğ¢ĞĞ Ğ¡ â€” ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
  python setup.py              # ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° + Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
  python setup.py --skip-data  # Ğ‘ĞµĞ· ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ°Ğ· (Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾)
  python setup.py --skip-train # Ğ‘ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
  python setup.py --gpu        # Ğ¡ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ CUDA GPU
  python setup.py --check      # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°
        """
    )
    parser.add_argument("--skip-data", action="store_true",
                        help="ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹")
    parser.add_argument("--skip-train", action="store_true",
                        help="ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹")
    parser.add_argument("--gpu", action="store_true",
                        help="Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ PyTorch Ñ CUDA")
    parser.add_argument("--check", action="store_true",
                        help="Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ")
    args = parser.parse_args()
    
    banner("ğŸ¤– Ğ¢ĞĞ Ğ¡ â€” ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹")
    
    start = time.time()
    
    if args.check:
        verify_system()
        return
    
    # 1. Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
    setup_venv()
    
    # 2. Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    install_dependencies(use_gpu=args.gpu)
    
    # 3. Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
    create_directories()
    
    # 4. ĞœĞ¾Ğ´ĞµĞ»Ğ¸
    download_models()
    
    # 5. Ğ‘Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
    if not args.skip_data:
        download_knowledge()
    else:
        info("Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°Ğ· Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (--skip-data)")
    
    # 6. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
    if not args.skip_train:
        train_models(use_gpu=args.gpu)
    else:
        info("ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (--skip-train)")
    
    # 7. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°
    verify_system()
    
    elapsed = time.time() - start
    minutes = int(elapsed // 60)
    seconds = int(elapsed % 60)
    print(f"  â±  Ğ’Ñ€ĞµĞ¼Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸: {minutes} Ğ¼Ğ¸Ğ½ {seconds} ÑĞµĞº")
    print()


if __name__ == "__main__":
    main()
