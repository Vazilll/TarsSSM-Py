"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  Whisper Vocabulary Boost ‚Äî –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ STT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–∞—é—â–∏–π –∫–æ—Ä–ø—É—Å –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç:
  1. –¢–æ–ø-1000 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ ‚Üí hotwords –¥–ª—è Whisper
  2. –ß–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å ‚Üí initial_prompt –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
  3. –î–æ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã ‚Üí —Å–ø–µ—Ü. –ª–µ–∫—Å–∏–∫–∞ –¢–ê–†–°

Whisper –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Å–ª–æ–≤ (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã, –∏–º–µ–Ω–∞, –∫–æ–º–∞–Ω–¥—ã).

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python training/whisper_boost.py
"""

import os
import sys
import re
import json
import logging
from pathlib import Path
from collections import Counter

ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger("Whisper.Boost")

# –°—Ç–æ–ø-—Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–µ), –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–µ—Å—É—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
STOP_WORDS = {
    "–∏", "–≤", "–Ω–∞", "—Å", "–ø–æ", "–¥–ª—è", "–æ—Ç", "–∏–∑", "—á—Ç–æ", "–∫–∞–∫",
    "—ç—Ç–æ", "–Ω–µ", "–Ω–æ", "–æ–Ω", "–æ–Ω–∞", "–æ–Ω–∏", "–µ–≥–æ", "–µ—ë", "–∏—Ö",
    "–±—ã–ª", "–±—ã–ª–∞", "–±—ã–ª–æ", "–±—ã–ª–∏", "–±—ã—Ç—å", "–µ—Å—Ç—å", "–±—É–¥–µ—Ç",
    "–∫", "–¥–æ", "–∑–∞", "–ø—Ä–∏", "–æ–±", "–æ", "—É", "–∞", "–∂–µ",
    "—Ç–æ", "–ª–∏", "–±—ã", "–≤–æ—Ç", "–µ—â—ë", "—É–∂–µ", "–≤—Å–µ", "–≤–µ—Å—å",
    "—Ç–∞–∫", "—Ç–æ–∂–µ", "—Ç–æ–ª—å–∫–æ", "—Ç–æ—Ç", "—Ç–∞", "—Ç–µ", "—ç—Ç–æ—Ç", "—ç—Ç–∞",
    "–Ω–µ—Ç", "–¥–∞", "–º–æ–∂–µ—Ç", "–º–æ–∂–Ω–æ", "–Ω—É–∂–Ω–æ", "–Ω–∞–¥–æ", "—Ç–∞–º",
    "—Ç—É—Ç", "–æ—á–µ–Ω—å", "–±–æ–ª–µ–µ", "–∫–æ–≥–¥–∞", "–≥–¥–µ", "–µ—Å–ª–∏", "—á–µ–º",
    "–∏–ª–∏", "–º–µ–∂–¥—É", "—á–µ—Ä–µ–∑", "–ø–æ—Å–ª–µ", "–ø–µ—Ä–µ–¥", "–Ω–∞–¥", "–ø–æ–¥",
    "—Ç–∞–∫–∂–µ", "–∫–æ—Ç–æ—Ä—ã–π", "–∫–æ—Ç–æ—Ä–∞—è", "–∫–æ—Ç–æ—Ä–æ–µ", "–∫–æ—Ç–æ—Ä—ã–µ",
    "–æ–¥–∏–Ω", "–¥–≤–∞", "—Ç—Ä–∏", "—á–µ—Ç—ã—Ä–µ", "–ø—è—Ç—å", "–ø–µ—Ä–≤—ã–π", "–≤—Ç–æ—Ä–æ–π",
    "–¥—Ä—É–≥–æ–π", "–∫–∞–∂–¥—ã–π", "—Å–≤–æ–π", "—ç—Ç–∏—Ö", "–≤—Å–µ—Ö", "–æ–¥–Ω–∞–∫–æ",
    "–∑–∞–ø—Ä–æ—Å", "–æ—Ç–≤–µ—Ç", "–≤–æ–ø—Ä–æ—Å", "–∫–æ–Ω—Ç–µ–∫—Å—Ç", "—Å–∏—Å—Ç–µ–º–∞",
}


def extract_keywords(text: str, top_k: int = 1000) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–ø-K –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    # –û—á–∏—Å—Ç–∫–∞ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    words = re.findall(r'[–∞-—è–ê-–Ø—ë–Åa-zA-Z]{3,}', text.lower())
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤
    meaningful = [w for w in words if w not in STOP_WORDS and len(w) > 2]
    
    # –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    freq = Counter(meaningful)
    
    # –¢–æ–ø-K –ø–æ —á–∞—Å—Ç–æ—Ç–µ
    return [word for word, count in freq.most_common(top_k)]


def extract_domain_terms(text: str, min_freq: int = 5) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞)."""
    # –ò—â–µ–º —Å–ª–æ–≤–∞ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã (–∏–º–µ–Ω–∞, —Ç–µ—Ä–º–∏–Ω—ã)
    proper_nouns = re.findall(r'\b([–ê-–Ø–ÅA-Z][–∞-—è—ëa-z]{2,})\b', text)
    freq = Counter(proper_nouns)
    
    # –ò—â–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã (–ª–∞—Ç–∏–Ω–∏—Ü–∞, –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã)
    tech_terms = re.findall(r'\b([A-Z]{2,}[a-z]*|[A-Z][a-z]+(?:[A-Z][a-z]+)+)\b', text)
    tech_freq = Counter(tech_terms)
    
    domain = []
    for word, count in freq.most_common(200):
        if count >= min_freq:
            domain.append(word)
    for word, count in tech_freq.most_common(100):
        if count >= min_freq:
            domain.append(word)
    
    return domain


def build_initial_prompt(keywords: list, max_words: int = 50) -> str:
    """–°–æ–∑–¥–∞—ë—Ç initial_prompt –¥–ª—è Whisper –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤."""
    # –ë–µ—Ä—ë–º —Å–∞–º—ã–µ —á–∞—Å—Ç–æ—Ç–Ω—ã–µ —Å–ª–æ–≤–∞ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    prompt_words = keywords[:max_words]
    return " ".join(prompt_words)


def create_whisper_config(data_dir: str = None, output_path: str = None):
    """
    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è Whisper –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
    
    –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª models/voice/whisper_context.json —Å–æ–¥–µ—Ä–∂–∏—Ç:
    - hotwords: —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –±—É—Å—Ç–∏–Ω–≥–∞
    - initial_prompt: –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è —Ñ—Ä–∞–∑–∞
    - domain_terms: —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
    """
    if data_dir is None:
        data_dir = str(ROOT / "data")
    if output_path is None:
        output_path = str(ROOT / "models" / "voice" / "whisper_context.json")
    
    logger.info("‚ïê" * 60)
    logger.info("  Whisper Vocabulary Boost")
    logger.info("‚ïê" * 60)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
    all_text = ""
    data_path = Path(data_dir)
    
    if not data_path.exists():
        logger.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {data_dir}")
        return False
    
    txt_files = sorted(data_path.glob("*.txt"))
    for f in txt_files:
        try:
            with open(f, 'r', encoding='utf-8') as fh:
                text = fh.read()
            all_text += " " + text
            logger.info(f"  üìÑ {f.name}: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤")
        except Exception:
            pass
    
    if not all_text:
        logger.warning("‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return False
    
    total_mb = len(all_text.encode('utf-8')) / (1024 * 1024)
    logger.info(f"\n  –ò—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {total_mb:.1f} MB")
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ
    logger.info("\n  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤...")
    keywords = extract_keywords(all_text, top_k=1000)
    logger.info(f"  ‚úì {len(keywords)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    
    logger.info("  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤...")
    domain_terms = extract_domain_terms(all_text)
    logger.info(f"  ‚úì {len(domain_terms)} –¥–æ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤")
    
    initial_prompt = build_initial_prompt(keywords, max_words=50)
    logger.info(f"  ‚úì Initial prompt: {len(initial_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # TARS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
    tars_commands = [
        "–¢–ê–†–°", "–¢–∞—Ä—Å", "—Ç–∞—Ä—Å",
        "–ø—Ä–∏–≤–µ—Ç", "–ø–æ–º–æ–≥–∏", "—Ä–∞—Å—Å–∫–∞–∂–∏", "–æ–±—ä—è—Å–Ω–∏", "–Ω–∞–π–¥–∏",
        "–æ—Ç–∫—Ä–æ–π", "–∑–∞–∫—Ä–æ–π", "–∑–∞–ø—É—Å—Ç–∏", "–æ—Å—Ç–∞–Ω–æ–≤–∏", "–≤—ã–∫–ª—é—á–∏",
        "–ø–æ–∫–∞–∂–∏", "—Å–∫–∞–∂–∏", "–Ω–∞–ø–æ–º–Ω–∏", "–∑–∞–ø–æ–º–Ω–∏", "–∑–∞–±—É–¥—å",
        "–ø–µ—Ä–µ–≤–µ–¥–∏", "–Ω–∞–ø–∏—à–∏", "–ø—Ä–æ—á–∏—Ç–∞–π", "–ø–æ—Å—á–∏—Ç–∞–π",
        "–∫–∞–∫–∞—è –ø–æ–≥–æ–¥–∞", "–∫–æ—Ç–æ—Ä—ã–π —á–∞—Å", "—á—Ç–æ –Ω–æ–≤–æ–≥–æ",
    ]
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º hotwords
    all_hotwords = list(set(keywords[:200] + domain_terms + tars_commands))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    config = {
        "hotwords": all_hotwords,
        "initial_prompt": initial_prompt,
        "domain_terms": domain_terms[:100],
        "tars_commands": tars_commands,
        "keywords_count": len(keywords),
        "corpus_size_mb": round(total_mb, 1),
    }
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\n  ‚úÖ Whisper –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
    logger.info(f"     {len(all_hotwords)} hotwords, prompt: {len(initial_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"     Whisper —Ç–µ–ø–µ—Ä—å –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¢–ê–†–°")
    
    return True


if __name__ == "__main__":
    create_whisper_config()
