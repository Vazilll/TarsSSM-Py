{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ TARS v3 ‚Äî Google Colab Full Training Pipeline\n",
                "\n",
                "**–ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¢–ê–†–° v3: –º–æ–∑–≥ + –≥–æ–ª–æ—Å (STT + TTS)**\n",
                "\n",
                "### –ü–æ–¥—Ö–æ–¥: –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è ‚Üí –î–æ–æ–±—É—á–µ–Ω–∏–µ (QAT)\n",
                "–°–Ω–∞—á–∞–ª–∞ –º–æ–¥–µ–ª—å –∫–≤–∞–Ω—Ç—É–µ—Ç—Å—è –≤ 1.58-bit, –∑–∞—Ç–µ–º –¥–æ–æ–±—É—á–∞–µ—Ç—Å—è –≤ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ —á–µ—Ä–µ–∑ STE.\n",
                "–≠—Ç–æ –¥–∞—ë—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —á–µ–º –∫–≤–∞–Ω—Ç–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è.\n",
                "\n",
                "### –§–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è:\n",
                "| # | –ú–æ–¥—É–ª—å | –ü–æ–¥—Ö–æ–¥ | –í—Ä–µ–º—è (T4) |\n",
                "|---|--------|--------|------------|\n",
                "| 2 | –†–µ—Ñ–ª–µ–∫—Å—ã | MinGRU Classifier | ~2 –º–∏–Ω |\n",
                "| 3 | MinGRU LM | System 1 –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä | ~30 –º–∏–Ω |\n",
                "| 4.1 | Mamba-2 Warmup | FP16 pretrain (3 —ç–ø–æ—Ö–∏) | ~1 —á |\n",
                "| 4.Q | **–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è** | FP16 ‚Üí 1.58-bit BitNet | ~1 –º–∏–Ω |\n",
                "| 4.2 | Mamba-2 Phase 2 | **1.58-bit STE** (WKV+Fusion) | ~1.5 —á |\n",
                "| 4.3 | Mamba-2 Phase 3 | **1.58-bit STE** (MoLE+Pool) | ~1 —á |\n",
                "| 4.4 | Mamba-2 Phase 4 | **1.58-bit STE** (RAG+Memory) | ~1 —á |\n",
                "| 7 | –í–∞–ª–∏–¥–∞—Ü–∏—è | –¢–µ—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è | ~5 –º–∏–Ω |\n",
                "| 8 | Whisper STT | LoRA fine-tune (base, —Ä—É—Å—Å–∫–∏–π) | ~40 –º–∏–Ω |\n",
                "| 9 | Piper TTS | VITS fine-tune (—Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å) | ~1-2 —á |\n",
                "| 10 | Voice INT8 | –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è ONNX + Whisper Boost | ~5 –º–∏–Ω |\n",
                "\n",
                "### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:\n",
                "1. **Runtime ‚Üí Change runtime type ‚Üí GPU (T4)**\n",
                "2. –ó–∞–ø—É—Å–∫–∞–π —è—á–µ–π–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É ‚ñ∂\n",
                "3. –ú–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞ **Google Drive**\n",
                "4. –ü—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏ Colab ‚Äî –∑–∞–ø—É—Å—Ç–∏ —è—á–µ–π–∫—É 0, –º–æ–¥–µ–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —Å Drive\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU + Google Drive + –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import os\n",
                "import time\n",
                "import shutil\n",
                "\n",
                "print(\"=\" * 65)\n",
                "print(\"  TARS v3 ‚Äî Quant-First Training Pipeline\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    GPU_NAME = torch.cuda.get_device_name(0)\n",
                "    VRAM_GB = torch.cuda.get_device_properties(0).total_mem / 1024**3\n",
                "    print(f\"  ‚úÖ GPU:  {GPU_NAME}\")\n",
                "    print(f\"  ‚úÖ VRAM: {VRAM_GB:.1f} GB\")\n",
                "    print(f\"  ‚úÖ CUDA: {torch.version.cuda}\")\n",
                "else:\n",
                "    print(\"  ‚ùå GPU –ù–ï –û–ë–ù–ê–†–£–ñ–ï–ù!\")\n",
                "    raise RuntimeError(\"GPU not available\")\n",
                "\n",
                "if VRAM_GB >= 35:\n",
                "    BATCH, ACCUM = 32, 2\n",
                "    WHISPER_BATCH, WHISPER_MODEL = 32, \"base\"\n",
                "    PIPER_BATCH = 32\n",
                "    GPU_TIER = \"A100\"\n",
                "elif VRAM_GB >= 14:\n",
                "    BATCH, ACCUM = 16, 4\n",
                "    WHISPER_BATCH, WHISPER_MODEL = 16, \"base\"\n",
                "    PIPER_BATCH = 16\n",
                "    GPU_TIER = \"T4\"\n",
                "else:\n",
                "    BATCH, ACCUM = 8, 8\n",
                "    WHISPER_BATCH, WHISPER_MODEL = 8, \"tiny\"\n",
                "    PIPER_BATCH = 8\n",
                "    GPU_TIER = \"Budget\"\n",
                "\n",
                "print(f\"  ‚ö° Tier: {GPU_TIER} (batch={BATCH}√ó{ACCUM}={BATCH*ACCUM})\")\n",
                "print(f\"  üé§ Whisper: {WHISPER_MODEL}\")\n",
                "\n",
                "SAVE_TO_DRIVE = True\n",
                "DRIVE_DIR = \"/content/drive/MyDrive/TARS_v3_models\"\n",
                "\n",
                "if SAVE_TO_DRIVE:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    os.makedirs(DRIVE_DIR, exist_ok=True)\n",
                "    print(f\"  üíæ Google Drive: {DRIVE_DIR}\")\n",
                "\n",
                "print(\"=\" * 65)\n",
                "T_START = time.time()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ + –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, shutil, glob\n",
                "\n",
                "REPO_URL = \"https://github.com/Vazilll/TarsSSM-Py.git\"\n",
                "WORK_DIR = \"/content/TarsSSM-Py\"\n",
                "\n",
                "if os.path.exists(os.path.join(WORK_DIR, \"mega_train.py\")):\n",
                "    print(\"‚úÖ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —É–∂–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω\")\n",
                "    !cd {WORK_DIR} && git pull --ff-only 2>/dev/null || true\n",
                "else:\n",
                "    !git clone {REPO_URL} {WORK_DIR}\n",
                "\n",
                "os.chdir(WORK_DIR)\n",
                "sys.path.insert(0, WORK_DIR)\n",
                "\n",
                "!pip install -q einops tqdm psutil sentencepiece tokenizers \\\n",
                "    sentence-transformers datasets transformers peft jiwer \\\n",
                "    faster-whisper onnxruntime sounddevice\n",
                "\n",
                "# ‚ïê‚ïê‚ïê –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –° DRIVE ‚ïê‚ïê‚ïê\n",
                "if SAVE_TO_DRIVE and os.path.exists(DRIVE_DIR):\n",
                "    restore_map = {\n",
                "        \"mamba2_final.pt\":   \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_phase3.pt\": \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_phase2.pt\": \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_phase1.pt\": \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_158bit.pt\": \"models/mamba2/mamba2_omega_158bit.pt\",\n",
                "        \"mamba2_fp16.pt\":   \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mingru.pt\":        \"models/mingru_weights.pt\",\n",
                "        \"reflex.pt\":        \"models/reflex/reflex_classifier.pt\",\n",
                "    }\n",
                "    restored = 0\n",
                "    for drive_name, local_path in restore_map.items():\n",
                "        drive_path = os.path.join(DRIVE_DIR, drive_name)\n",
                "        local_full = os.path.join(WORK_DIR, local_path)\n",
                "        if os.path.exists(drive_path) and not os.path.exists(local_full):\n",
                "            os.makedirs(os.path.dirname(local_full), exist_ok=True)\n",
                "            shutil.copy2(drive_path, local_full)\n",
                "            size_mb = os.path.getsize(local_full) / 1024 / 1024\n",
                "            print(f\"  üîÑ Drive ‚Üí {local_path} ({size_mb:.1f} MB)\")\n",
                "            restored += 1\n",
                "    drive_whisper = os.path.join(DRIVE_DIR, \"whisper_ru_lora\")\n",
                "    local_whisper = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_ru_lora\")\n",
                "    if os.path.exists(drive_whisper) and not os.path.exists(local_whisper):\n",
                "        shutil.copytree(drive_whisper, local_whisper)\n",
                "        print(f\"  üîÑ Drive ‚Üí whisper_ru_lora/\")\n",
                "        restored += 1\n",
                "    if restored > 0:\n",
                "        print(f\"  ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {restored} –º–æ–¥–µ–ª–µ–π —Å Drive\")\n",
                "    else:\n",
                "        print(\"  ‚Ñπ –ù–∞ Drive –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π ‚Äî –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è\")\n",
                "\n",
                "def save_to_drive(src_path, name=None):\n",
                "    if not SAVE_TO_DRIVE or not os.path.exists(src_path):\n",
                "        return\n",
                "    dst = os.path.join(DRIVE_DIR, name or os.path.basename(src_path))\n",
                "    shutil.copy2(src_path, dst)\n",
                "    size_mb = os.path.getsize(dst) / 1024 / 1024\n",
                "    print(f\"  üíæ ‚Üí Drive: {name or os.path.basename(src_path)} ({size_mb:.1f} MB)\")\n",
                "\n",
                "print(\"‚úÖ Ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (Wiki + HF + Identity)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "os.makedirs(\"data\", exist_ok=True)\n",
                "\n",
                "# Wikipedia\n",
                "wiki_path = os.path.join(WORK_DIR, \"data\", \"wiki_ru.txt\")\n",
                "if os.path.exists(wiki_path) and os.path.getsize(wiki_path) > 100_000:\n",
                "    print(f\"üìö Wikipedia: —É–∂–µ –µ—Å—Ç—å ({os.path.getsize(wiki_path)/1024/1024:.1f} MB)\")\n",
                "else:\n",
                "    print(\"üìö –°–∫–∞—á–∏–≤–∞–Ω–∏–µ Wikipedia (50 000 —Å—Ç–∞—Ç–µ–π)...\")\n",
                "    !python training/download_wiki.py --count 50000\n",
                "\n",
                "# HuggingFace\n",
                "hf_files = glob.glob(os.path.join(WORK_DIR, \"data\", \"hf_*.txt\"))\n",
                "if len(hf_files) >= 1:\n",
                "    total_mb = sum(os.path.getsize(f) for f in hf_files) / 1024 / 1024\n",
                "    print(f\"ü§ó HuggingFace: —É–∂–µ –µ—Å—Ç—å ({len(hf_files)} —Ñ–∞–π–ª–æ–≤, {total_mb:.0f} MB)\")\n",
                "else:\n",
                "    !python training/download_hf_dataset.py --preset all\n",
                "\n",
                "# TARS Identity (self-description)\n",
                "identity_path = os.path.join(WORK_DIR, \"data\", \"tars_identity.txt\")\n",
                "if os.path.exists(identity_path):\n",
                "    size_kb = os.path.getsize(identity_path) / 1024\n",
                "    print(f\"üß¨ –¢–ê–†–° Identity: {size_kb:.0f} KB (—Å–∞–º–æ–æ–ø–∏—Å–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã)\")\n",
                "else:\n",
                "    print(\"‚ö† tars_identity.txt –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
                "\n",
                "# LEANN\n",
                "try:\n",
                "    emb_path = os.path.join(WORK_DIR, \"models\", \"embeddings\")\n",
                "    if not os.path.exists(emb_path):\n",
                "        from sentence_transformers import SentenceTransformer\n",
                "        SentenceTransformer('all-MiniLM-L6-v2').save(emb_path)\n",
                "    print(f\"üß† Embeddings: OK\")\n",
                "except Exception as e:\n",
                "    print(f\"  ‚ö† Embeddings: {e}\")\n",
                "\n",
                "try:\n",
                "    sys.path.insert(0, os.path.join(WORK_DIR, \"training\"))\n",
                "    from ingest_to_leann import ingest_all\n",
                "    ingest_all()\n",
                "    print(\"üß† LEANN: OK\")\n",
                "except Exception as e:\n",
                "    print(f\"  ‚Ñπ LEANN: {e}\")\n",
                "\n",
                "data_files = [f for f in glob.glob(os.path.join(WORK_DIR, \"data\", \"*\")) if os.path.isfile(f)]\n",
                "print(f\"\\nüìä –ò—Ç–æ–≥–æ: {sum(os.path.getsize(f) for f in data_files)/1024/1024:.0f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üß† –ú–û–ó–ì\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 2: –†–µ—Ñ–ª–µ–∫—Å—ã (~2 –º–∏–Ω)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(\"  –§–∞–∑–∞ 2: –†–µ—Ñ–ª–µ–∫—Å—ã (MinGRU Classifier)\")\n",
                "print(\"=\"*65)\n",
                "!python training/train_reflex.py --epochs 100 --lr 0.002\n",
                "save_to_drive(\"models/reflex/reflex_classifier.pt\", \"reflex.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 3: MinGRU LM ‚Äî System 1 (~30 –º–∏–Ω)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(\"  –§–∞–∑–∞ 3: MinGRU Language Model\")\n",
                "print(\"=\"*65)\n",
                "!python training/train_mingru.py \\\n",
                "    --epochs 50 --lr 3e-3 --dim 512 --layers 6 \\\n",
                "    --batch 32 --seq_len 256 --augment\n",
                "save_to_drive(\"models/mingru_weights.pt\", \"mingru.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 4.1: FP16 Warmup (3 —ç–ø–æ—Ö–∏)\n",
                "\n",
                "–ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–≥—Ä–µ–≤ –≤ FP16 ‚Äî –º–æ–¥–µ–ª—å —É—á–∏—Ç –±–∞–∑–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ **—Å–≤–æ—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É** –∏–∑ `tars_identity.txt`.\n",
                "\n",
                "~1 —á–∞—Å –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, os\n",
                "\n",
                "device = \"cuda\"\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0)} ({VRAM_GB:.0f} GB)\")\n",
                "print(f\"Batch: {BATCH}√ó{ACCUM} = {BATCH*ACCUM} effective\")\n",
                "\n",
                "# Transfer embedding MinGRU ‚Üí Mamba-2\n",
                "emb_args = \"\"\n",
                "mingru_path = os.path.join(WORK_DIR, \"models\", \"mingru_weights.pt\")\n",
                "if os.path.exists(mingru_path):\n",
                "    cp = torch.load(mingru_path, map_location='cpu', weights_only=False)\n",
                "    state = cp.get('model_state_dict', cp)\n",
                "    for k in state:\n",
                "        if 'shared_embedding' in k or 'emb.weight' in k:\n",
                "            emb_dir = os.path.join(WORK_DIR, \"models\", \"tars_v3\")\n",
                "            os.makedirs(emb_dir, exist_ok=True)\n",
                "            emb_path = os.path.join(emb_dir, \"_transfer_embedding.pt\")\n",
                "            torch.save(state[k], emb_path)\n",
                "            emb_args = f\"--pretrained_emb {emb_path}\"\n",
                "            print(f\"üîó Transfer embedding: {state[k].shape}\")\n",
                "            break\n",
                "\n",
                "BASE = f\"--d_model 768 --n_layers 12 --vocab_size 256 --batch {BATCH} --accum_steps {ACCUM} --device {device} --curriculum --label_smoothing 0.1 {emb_args}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Phase 1: FP16 Warmup ‚Äî 3 —ç–ø–æ—Ö–∏ (–≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)\n",
                "print(\"=\"*65)\n",
                "print(\"  Phase 4.1: FP16 Warmup (3 —ç–ø–æ—Ö–∏, –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)\")\n",
                "print(\"=\"*65)\n",
                "!python training/train_mamba2.py {BASE} --epochs 3 --lr 3e-4 --phase 1 --seq_len 256\n",
                "save_to_drive(\"models/mamba2/mamba2_omega.pt\", \"mamba2_fp16.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 4.Q: –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è FP16 ‚Üí 1.58-bit\n",
                "\n",
                "**–ö–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç:** –∫–≤–∞–Ω—Ç—É–µ–º –°–ù–ê–ß–ê–õ–ê, –ø–æ—Ç–æ–º –¥–æ–æ–±—É—á–∞–µ–º.\n",
                "\n",
                "–ú–æ–¥–µ–ª—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –≤ 1.58-bit (BitNet), –∑–∞—Ç–µ–º –≤—Å–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ñ–∞–∑—ã –∏–¥—É—Ç –≤ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ —á–µ—Ä–µ–∑ STE.\n",
                "\n",
                "~1 –º–∏–Ω"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è: FP16 ‚Üí 1.58-bit + STE –¥–æ–æ–±—É—á–µ–Ω–∏–µ (5 —ç–ø–æ—Ö)\n",
                "print(\"=\"*65)\n",
                "print(\"  Phase 4.Q: –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è FP16 ‚Üí 1.58-bit BitNet + STE warmup\")\n",
                "print(\"=\"*65)\n",
                "\n",
                "fp16_path = os.path.join(WORK_DIR, \"models\", \"mamba2\", \"mamba2_omega.pt\")\n",
                "if os.path.exists(fp16_path):\n",
                "    fp16_mb = os.path.getsize(fp16_path) / 1024 / 1024\n",
                "    print(f\"  FP16 –º–æ–¥–µ–ª—å: {fp16_mb:.0f} MB\")\n",
                "    # –§–∞–∑–∞ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏: –∑–∞–≥—Ä—É–∂–∞–µ—Ç FP16, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ 1.58-bit, –¥–æ–æ–±—É—á–∞–µ—Ç 5 —ç–ø–æ—Ö\n",
                "    !python training/train_mamba2.py {BASE} \\\n",
                "        --epochs 5 --lr 5e-5 --phase 1 --quant \\\n",
                "        --resume --seq_len 256\n",
                "    save_to_drive(\"models/mamba2/mamba2_omega_158bit.pt\", \"mamba2_158bit.pt\")\n",
                "else:\n",
                "    print(\"‚ö† FP16 –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 4.2: WKV + Fusion in 1.58-bit (5 —ç–ø–æ—Ö)\n",
                "\n",
                "–î–æ–æ–±—É—á–µ–Ω–∏–µ **—É–∂–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω–æ–π** –º–æ–¥–µ–ª–∏. SSD –∑–∞–º–æ—Ä–æ–∂–µ–Ω, —Ç—Ä–µ–Ω–∏—Ä—É—é—Ç—Å—è WKV + Fusion + Œ©-SSM + NoveltyGate.\n",
                "\n",
                "~1.5 —á–∞—Å–∞ –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(\"  Phase 4.2: WKV + Fusion (1.58-bit STE)\")\n",
                "print(\"=\"*65)\n",
                "!python training/train_mamba2.py {BASE} \\\n",
                "    --epochs 5 --lr 1e-4 --phase 2 --quant \\\n",
                "    --resume --seq_len 512\n",
                "save_to_drive(\"models/mamba2/mamba2_omega_158bit.pt\", \"mamba2_158bit_p2.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 4.3: MoLE + MatrixPool in 1.58-bit (3 —ç–ø–æ—Ö–∏)\n",
                "\n",
                "~1 —á–∞—Å –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(\"  Phase 4.3: MoLE + MatrixPool (1.58-bit STE)\")\n",
                "print(\"=\"*65)\n",
                "!python training/train_mamba2.py {BASE} \\\n",
                "    --epochs 3 --lr 3e-5 --phase 3 --quant \\\n",
                "    --resume --seq_len 512\n",
                "save_to_drive(\"models/mamba2/mamba2_omega_158bit.pt\", \"mamba2_158bit_p3.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 4.4: RAG + Memory in 1.58-bit (3 —ç–ø–æ—Ö–∏)\n",
                "\n",
                "~1 —á–∞—Å –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(\"  Phase 4.4: RAG + Memory + Spine (1.58-bit STE)\")\n",
                "print(\"=\"*65)\n",
                "!python training/train_mamba2.py {BASE} \\\n",
                "    --epochs 3 --lr 1.5e-5 --phase 4 --quant \\\n",
                "    --resume --seq_len 512\n",
                "save_to_drive(\"models/mamba2/mamba2_omega_158bit.pt\", \"mamba2_158bit.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 7: –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–∑–≥–∞"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, sys, gc\n",
                "gc.collect()\n",
                "torch.cuda.empty_cache()\n",
                "sys.path.insert(0, WORK_DIR)\n",
                "\n",
                "print(\"=\"*65)\n",
                "print(\"  –§–∞–∑–∞ 7: –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–∑–≥–∞\")\n",
                "print(\"=\"*65)\n",
                "\n",
                "try:\n",
                "    from brain.tokenizer import TarsTokenizer\n",
                "    from brain.mamba2.model import TarsMamba2LM\n",
                "\n",
                "    tokenizer = TarsTokenizer()\n",
                "    model, ckpt = TarsMamba2LM.load_pretrained(device=\"cuda\")\n",
                "    model.eval()\n",
                "\n",
                "    if ckpt:\n",
                "        params = sum(p.numel() for p in model.parameters())\n",
                "        print(f\"‚úÖ Model: {ckpt}\")\n",
                "        print(f\"‚úÖ Params: {params:,}\\n\")\n",
                "\n",
                "        for prompt in [\"–ø—Ä–∏–≤–µ—Ç\", \"–∫—Ç–æ —Ç—ã\", \"—á—Ç–æ —Ç–∞–∫–æ–µ\", \"–∏–∑ —á–µ–≥–æ —Ç—ã —Å–æ—Å—Ç–æ–∏—à—å\", \"–ø–æ–º–æ–≥–∏\"]:\n",
                "            tokens = tokenizer.encode(prompt)\n",
                "            input_ids = torch.tensor([tokens], dtype=torch.long, device=\"cuda\")\n",
                "            with torch.no_grad():\n",
                "                logits = model(input_ids)\n",
                "            probs = torch.softmax(logits[0, -1, :], dim=-1)\n",
                "            top5 = torch.topk(probs, 5)\n",
                "            preds = [f\"'{tokenizer.decode([i])}'({p:.1%})\" for i, p in zip(top5.indices.tolist(), top5.values.tolist())]\n",
                "            print(f\"  '{prompt}' ‚Üí {', '.join(preds)}\")\n",
                "        print(\"\\n‚úÖ Brain works!\")\n",
                "    else:\n",
                "        print(\"‚ö† No weights\")\n",
                "    del model\n",
                "    torch.cuda.empty_cache()\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üé§ –ì–û–õ–û–°\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 8: Whisper STT ‚Äî base (74M, LoRA, ~40 –º–∏–Ω)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(f\"  –§–∞–∑–∞ 8: Whisper {WHISPER_MODEL} LoRA Fine-tune (Russian STT)\")\n",
                "print(\"=\"*65)\n",
                "\n",
                "import gc, torch\n",
                "gc.collect()\n",
                "torch.cuda.empty_cache()\n",
                "\n",
                "!python training/train_whisper.py \\\n",
                "    --model {WHISPER_MODEL} --device cuda \\\n",
                "    --samples 10000 --val_samples 1000 \\\n",
                "    --epochs 5 --batch {WHISPER_BATCH} \\\n",
                "    --lr 1e-3 --lora_r 32\n",
                "\n",
                "whisper_dir = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_ru_lora\")\n",
                "if os.path.exists(whisper_dir) and SAVE_TO_DRIVE:\n",
                "    drive_whisper = os.path.join(DRIVE_DIR, \"whisper_ru_lora\")\n",
                "    if os.path.exists(drive_whisper):\n",
                "        shutil.rmtree(drive_whisper)\n",
                "    shutil.copytree(whisper_dir, drive_whisper)\n",
                "    print(f\"  üíæ ‚Üí Drive: whisper_ru_lora/\")\n",
                "    print(\"‚úÖ Whisper STT –æ–±—É—á–µ–Ω!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 9: Piper TTS (~1-2 —á)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(\"  –§–∞–∑–∞ 9: Piper TTS Fine-tune (Russian Voice)\")\n",
                "print(\"=\"*65)\n",
                "\n",
                "gc.collect()\n",
                "torch.cuda.empty_cache()\n",
                "!pip install -q piper-tts piper-phonemize 2>/dev/null || true\n",
                "\n",
                "!python training/train_piper.py --epochs 1000 --max_samples 3000 --batch {PIPER_BATCH}\n",
                "\n",
                "piper_onnx = os.path.join(WORK_DIR, \"models\", \"voice\", \"tars_voice_ru.onnx\")\n",
                "if os.path.exists(piper_onnx):\n",
                "    save_to_drive(piper_onnx, \"tars_voice_ru.onnx\")\n",
                "    print(\"‚úÖ Piper TTS –æ–±—É—á–µ–Ω!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 10: Whisper Boost + Voice INT8 (~5 –º–∏–Ω)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*65)\n",
                "print(\"  –§–∞–∑–∞ 10: Whisper Boost + Voice INT8\")\n",
                "print(\"=\"*65)\n",
                "\n",
                "!python training/whisper_boost.py\n",
                "whisper_ctx = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_context.json\")\n",
                "if os.path.exists(whisper_ctx):\n",
                "    save_to_drive(whisper_ctx, \"whisper_context.json\")\n",
                "\n",
                "!python training/quantize_voice.py\n",
                "print(\"\\n‚úÖ Voice pipeline done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üì¶ –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil, json, time\n",
                "\n",
                "OUTPUT_DIR = \"/content/tars_v3_output\"\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "print(\"=\"*65)\n",
                "print(\"  –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞\")\n",
                "print(\"=\"*65)\n",
                "\n",
                "model_files = {\n",
                "    \"mamba2_158bit.pt\": os.path.join(WORK_DIR, \"models\", \"mamba2\", \"mamba2_omega_158bit.pt\"),\n",
                "    \"mamba2_fp16.pt\":   os.path.join(WORK_DIR, \"models\", \"mamba2\", \"mamba2_omega.pt\"),\n",
                "    \"mingru.pt\":        os.path.join(WORK_DIR, \"models\", \"mingru_weights.pt\"),\n",
                "    \"reflex.pt\":        os.path.join(WORK_DIR, \"models\", \"reflex\", \"reflex_classifier.pt\"),\n",
                "    \"tars_voice_ru.onnx\": os.path.join(WORK_DIR, \"models\", \"voice\", \"tars_voice_ru.onnx\"),\n",
                "    \"whisper_context.json\": os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_context.json\"),\n",
                "}\n",
                "\n",
                "saved = []\n",
                "for name, src in model_files.items():\n",
                "    if os.path.exists(src):\n",
                "        shutil.copy2(src, os.path.join(OUTPUT_DIR, name))\n",
                "        mb = os.path.getsize(src) / 1024 / 1024\n",
                "        print(f\"  ‚úÖ {name} ({mb:.1f} MB)\")\n",
                "        saved.append(name)\n",
                "        save_to_drive(src, name)\n",
                "    else:\n",
                "        print(f\"  ‚è≠ {name}\")\n",
                "\n",
                "# Whisper LoRA\n",
                "wl_src = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_ru_lora\")\n",
                "wl_dst = os.path.join(OUTPUT_DIR, \"whisper_ru_lora\")\n",
                "if os.path.exists(wl_src):\n",
                "    if os.path.exists(wl_dst): shutil.rmtree(wl_dst)\n",
                "    shutil.copytree(wl_src, wl_dst)\n",
                "    print(f\"  ‚úÖ whisper_ru_lora/\")\n",
                "    saved.append(\"whisper_ru_lora/\")\n",
                "\n",
                "# Archive\n",
                "arc = shutil.make_archive(\"/content/tars_v3_full\", 'gztar', OUTPUT_DIR)\n",
                "if SAVE_TO_DRIVE:\n",
                "    shutil.copy2(arc, os.path.join(DRIVE_DIR, \"tars_v3_full.tar.gz\"))\n",
                "\n",
                "total_time = time.time() - T_START\n",
                "print(f\"\\n{'='*65}\")\n",
                "print(f\"  –ò–¢–û–ì–û: {total_time/3600:.1f}—á | {len(saved)} –º–æ–¥–µ–ª–µ–π\")\n",
                "for m in saved: print(f\"     ‚úÖ {m}\")\n",
                "print(f\"  üìÅ {arc} ({os.path.getsize(arc)/1024/1024:.0f} MB)\")\n",
                "print(f\"  üíæ {DRIVE_DIR}\")\n",
                "print(f\"{'='*65}\")\n",
                "print(f\"  üéØ –¢–ê–†–° v3 –û–ë–£–ß–ï–ù (Quant-First)!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "files.download(\"/content/tars_v3_full.tar.gz\")"
            ]
        }
    ]
}