{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ TARS v3 ‚Äî Google Colab Full Training Pipeline\n",
                "\n",
                "**–ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¢–ê–†–° v3: –º–æ–∑–≥ + –≥–æ–ª–æ—Å (STT + TTS)**\n",
                "\n",
                "### –§–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è:\n",
                "| # | –ú–æ–¥—É–ª—å | –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã | –í—Ä–µ–º—è (T4) |\n",
                "|---|--------|------------|------------|\n",
                "| 2 | –†–µ—Ñ–ª–µ–∫—Å—ã | MinGRU Classifier | ~2 –º–∏–Ω |\n",
                "| 3 | MinGRU LM | System 1 (–±—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è) | ~30 –º–∏–Ω |\n",
                "| 4 | Mamba-2 Brain | SSD + WKV + Œ©-SSM + MoLE + WaveConsolidation | ~3-5 —á |\n",
                "| 5 | –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è 1.58-bit | BitNet STE fine-tune (5 —ç–ø–æ—Ö) | ~20 –º–∏–Ω |\n",
                "| 7 | –í–∞–ª–∏–¥–∞—Ü–∏—è | –¢–µ—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è | ~5 –º–∏–Ω |\n",
                "| 8 | Whisper STT | LoRA fine-tune (base, —Ä—É—Å—Å–∫–∏–π) | ~40 –º–∏–Ω |\n",
                "| 9 | Piper TTS | VITS fine-tune (—Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å) | ~1-2 —á |\n",
                "| 10 | Voice INT8 | –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è ONNX + Whisper Boost | ~5 –º–∏–Ω |\n",
                "\n",
                "### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:\n",
                "1. **Runtime ‚Üí Change runtime type ‚Üí GPU (T4)**\n",
                "2. –ó–∞–ø—É—Å–∫–∞–π —è—á–µ–π–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É ‚ñ∂\n",
                "3. –ú–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞ **Google Drive**\n",
                "4. –ü—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏ Colab ‚Äî –∑–∞–ø—É—Å—Ç–∏ —è—á–µ–π–∫—É 0 –∏ –Ω—É–∂–Ω—É—é —Ñ–∞–∑—É –∑–∞–Ω–æ–≤–æ (–º–æ–¥–µ–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —Å Drive)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU + Google Drive + –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import os\n",
                "import time\n",
                "import shutil\n",
                "\n",
                "print(\"=\" * 65)\n",
                "print(\"  TARS v3 ‚Äî Google Colab Full Training Pipeline\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    GPU_NAME = torch.cuda.get_device_name(0)\n",
                "    VRAM_GB = torch.cuda.get_device_properties(0).total_mem / 1024**3\n",
                "    print(f\"  ‚úÖ GPU:  {GPU_NAME}\")\n",
                "    print(f\"  ‚úÖ VRAM: {VRAM_GB:.1f} GB\")\n",
                "    print(f\"  ‚úÖ CUDA: {torch.version.cuda}\")\n",
                "else:\n",
                "    print(\"  ‚ùå GPU –ù–ï –û–ë–ù–ê–†–£–ñ–ï–ù!\")\n",
                "    print(\"  ‚Üí Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\")\n",
                "    raise RuntimeError(\"GPU not available\")\n",
                "\n",
                "# –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ GPU\n",
                "if VRAM_GB >= 35:     # A100 (40GB)\n",
                "    BATCH, ACCUM = 32, 2\n",
                "    WHISPER_BATCH = 32\n",
                "    WHISPER_MODEL = \"base\"   # 74M params ‚Äî –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ\n",
                "    PIPER_BATCH = 32\n",
                "    GPU_TIER = \"A100\"\n",
                "elif VRAM_GB >= 14:   # T4 (16GB)\n",
                "    BATCH, ACCUM = 16, 4\n",
                "    WHISPER_BATCH = 16\n",
                "    WHISPER_MODEL = \"base\"   # 74M ‚Äî –ø–æ–º–µ—â–∞–µ—Ç—Å—è –Ω–∞ T4\n",
                "    PIPER_BATCH = 16\n",
                "    GPU_TIER = \"T4\"\n",
                "else:                 # K80 / free\n",
                "    BATCH, ACCUM = 8, 8\n",
                "    WHISPER_BATCH = 8\n",
                "    WHISPER_MODEL = \"tiny\"   # 39M ‚Äî –¥–ª—è —Å–ª–∞–±—ã—Ö GPU\n",
                "    PIPER_BATCH = 8\n",
                "    GPU_TIER = \"Budget\"\n",
                "\n",
                "print(f\"  ‚ö° Tier: {GPU_TIER} (batch={BATCH}√ó{ACCUM}={BATCH*ACCUM})\")\n",
                "print(f\"  üé§ Whisper: {WHISPER_MODEL}\")\n",
                "\n",
                "# Google Drive ‚Äî –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤\n",
                "SAVE_TO_DRIVE = True\n",
                "DRIVE_DIR = \"/content/drive/MyDrive/TARS_v3_models\"\n",
                "\n",
                "if SAVE_TO_DRIVE:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    os.makedirs(DRIVE_DIR, exist_ok=True)\n",
                "    print(f\"  üíæ Google Drive: {DRIVE_DIR}\")\n",
                "\n",
                "print(\"=\" * 65)\n",
                "\n",
                "T_START = time.time()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è + –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, shutil, glob\n",
                "\n",
                "REPO_URL = \"https://github.com/Vazilll/TarsSSM-Py.git\"\n",
                "WORK_DIR = \"/content/TarsSSM-Py\"\n",
                "\n",
                "if os.path.exists(os.path.join(WORK_DIR, \"mega_train.py\")):\n",
                "    print(\"‚úÖ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —É–∂–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω\")\n",
                "    !cd {WORK_DIR} && git pull --ff-only 2>/dev/null || true\n",
                "else:\n",
                "    print(f\"üì• –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ {REPO_URL}...\")\n",
                "    !git clone {REPO_URL} {WORK_DIR}\n",
                "\n",
                "os.chdir(WORK_DIR)\n",
                "sys.path.insert(0, WORK_DIR)\n",
                "\n",
                "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
                "!pip install -q einops tqdm psutil sentencepiece tokenizers \\\n",
                "    sentence-transformers datasets transformers peft jiwer \\\n",
                "    faster-whisper onnxruntime sounddevice\n",
                "\n",
                "print(f\"\\nüìÇ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}\")\n",
                "print(\"‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã\")\n",
                "\n",
                "# ‚ïê‚ïê‚ïê –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –° DRIVE ‚ïê‚ïê‚ïê\n",
                "# –ï—Å–ª–∏ Colab –æ—Ç–∫–ª—é—á–∏–ª—Å—è ‚Äî –º–æ–¥–µ–ª–∏ —É–∂–µ –Ω–∞ Drive, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º\n",
                "if SAVE_TO_DRIVE and os.path.exists(DRIVE_DIR):\n",
                "    restore_map = {\n",
                "        # Drive file ‚Üí Local path\n",
                "        \"mamba2_final.pt\":   \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_phase3.pt\": \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_phase2.pt\": \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_phase1.pt\": \"models/mamba2/mamba2_omega.pt\",\n",
                "        \"mamba2_158bit.pt\": \"models/mamba2/mamba2_omega_158bit.pt\",\n",
                "        \"mingru.pt\":        \"models/mingru_weights.pt\",\n",
                "        \"reflex.pt\":        \"models/reflex/reflex_classifier.pt\",\n",
                "    }\n",
                "    restored = 0\n",
                "    for drive_name, local_path in restore_map.items():\n",
                "        drive_path = os.path.join(DRIVE_DIR, drive_name)\n",
                "        local_full = os.path.join(WORK_DIR, local_path)\n",
                "        if os.path.exists(drive_path) and not os.path.exists(local_full):\n",
                "            os.makedirs(os.path.dirname(local_full), exist_ok=True)\n",
                "            shutil.copy2(drive_path, local_full)\n",
                "            size_mb = os.path.getsize(local_full) / 1024 / 1024\n",
                "            print(f\"  üîÑ Drive ‚Üí {local_path} ({size_mb:.1f} MB)\")\n",
                "            restored += 1\n",
                "    # Whisper LoRA directory\n",
                "    drive_whisper = os.path.join(DRIVE_DIR, \"whisper_ru_lora\")\n",
                "    local_whisper = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_ru_lora\")\n",
                "    if os.path.exists(drive_whisper) and not os.path.exists(local_whisper):\n",
                "        shutil.copytree(drive_whisper, local_whisper)\n",
                "        print(f\"  üîÑ Drive ‚Üí whisper_ru_lora/\")\n",
                "        restored += 1\n",
                "    if restored > 0:\n",
                "        print(f\"  ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {restored} –º–æ–¥–µ–ª–µ–π —Å Google Drive\")\n",
                "        print(f\"  ‚Üí –ú–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —É–∂–µ –æ–±—É—á–µ–Ω–Ω—ã–µ —Ñ–∞–∑—ã!\")\n",
                "    else:\n",
                "        print(\"  ‚Ñπ –ù–∞ Drive –Ω–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –º–æ–¥–µ–ª–µ–π ‚Äî –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è\")\n",
                "\n",
                "# –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ Drive\n",
                "def save_to_drive(src_path, name=None):\n",
                "    \"\"\"–ö–æ–ø–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –Ω–∞ Google Drive –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\"\"\"\n",
                "    if not SAVE_TO_DRIVE or not os.path.exists(src_path):\n",
                "        return\n",
                "    dst = os.path.join(DRIVE_DIR, name or os.path.basename(src_path))\n",
                "    shutil.copy2(src_path, dst)\n",
                "    size_mb = os.path.getsize(dst) / 1024 / 1024\n",
                "    print(f\"  üíæ ‚Üí Drive: {name or os.path.basename(src_path)} ({size_mb:.1f} MB)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "os.makedirs(\"data\", exist_ok=True)\n",
                "\n",
                "# Wikipedia (50–∫ —Å—Ç–∞—Ç–µ–π)\n",
                "wiki_path = os.path.join(WORK_DIR, \"data\", \"wiki_ru.txt\")\n",
                "if os.path.exists(wiki_path) and os.path.getsize(wiki_path) > 100_000:\n",
                "    size_mb = os.path.getsize(wiki_path) / 1024 / 1024\n",
                "    print(f\"üìö Wikipedia: —É–∂–µ –µ—Å—Ç—å ({size_mb:.1f} MB)\")\n",
                "else:\n",
                "    print(\"üìö –°–∫–∞—á–∏–≤–∞–Ω–∏–µ Wikipedia (50 000 —Å—Ç–∞—Ç–µ–π)...\")\n",
                "    !python training/download_wiki.py --count 50000\n",
                "\n",
                "# HuggingFace datasets\n",
                "hf_files = glob.glob(os.path.join(WORK_DIR, \"data\", \"hf_*.txt\"))\n",
                "if len(hf_files) >= 1:\n",
                "    total_mb = sum(os.path.getsize(f) for f in hf_files) / 1024 / 1024\n",
                "    print(f\"ü§ó HuggingFace: —É–∂–µ –µ—Å—Ç—å ({len(hf_files)} —Ñ–∞–π–ª–æ–≤, {total_mb:.0f} MB)\")\n",
                "else:\n",
                "    print(\"ü§ó –°–∫–∞—á–∏–≤–∞–Ω–∏–µ HuggingFace –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...\")\n",
                "    !python training/download_hf_dataset.py --preset all\n",
                "\n",
                "# LEANN embedding model\n",
                "try:\n",
                "    emb_path = os.path.join(WORK_DIR, \"models\", \"embeddings\")\n",
                "    if not os.path.exists(emb_path):\n",
                "        from sentence_transformers import SentenceTransformer\n",
                "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "        model.save(emb_path)\n",
                "    print(f\"üß† Embedding model: {emb_path}\")\n",
                "except Exception as e:\n",
                "    print(f\"  ‚ö† Embeddings: {e}\")\n",
                "\n",
                "# LEANN ingest\n",
                "try:\n",
                "    sys.path.insert(0, os.path.join(WORK_DIR, \"training\"))\n",
                "    from ingest_to_leann import ingest_all\n",
                "    ingest_all()\n",
                "    print(\"üß† LEANN –∑–∞–ø–æ–ª–Ω–µ–Ω–∞\")\n",
                "except Exception as e:\n",
                "    print(f\"  ‚Ñπ LEANN: {e} (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)\")\n",
                "\n",
                "data_files = [f for f in glob.glob(os.path.join(WORK_DIR, \"data\", \"*\")) if os.path.isfile(f)]\n",
                "total = sum(os.path.getsize(f) for f in data_files)\n",
                "print(f\"\\nüìä –ò—Ç–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö: {total / 1024 / 1024:.0f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üß† –ú–û–ó–ì ‚Äî –§–∞–∑—ã 2-7\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 2: –†–µ—Ñ–ª–µ–∫—Å—ã (MinGRU Classifier)\n",
                "\n",
                "~2 –º–∏–Ω –Ω–∞ GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 65)\n",
                "print(\"  –§–∞–∑–∞ 2: –†–µ—Ñ–ª–µ–∫—Å—ã (MinGRU Classifier)\")\n",
                "print(\"=\" * 65)\n",
                "!python training/train_reflex.py --epochs 100 --lr 0.002\n",
                "save_to_drive(\"models/reflex/reflex_classifier.pt\", \"reflex.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 3: MinGRU Language Model (System 1)\n",
                "\n",
                "–û–±—É—á–∞–µ–º—ã–µ –º–æ–¥—É–ª–∏: **MinGRU cells, embedding, LM head, Œ©-SSM context**\n",
                "\n",
                "~30 –º–∏–Ω –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 65)\n",
                "print(\"  –§–∞–∑–∞ 3: MinGRU Language Model (System 1)\")\n",
                "print(\"=\" * 65)\n",
                "!python training/train_mingru.py \\\n",
                "    --epochs 50 \\\n",
                "    --lr 3e-3 \\\n",
                "    --dim 512 \\\n",
                "    --layers 6 \\\n",
                "    --batch 32 \\\n",
                "    --seq_len 256 \\\n",
                "    --augment\n",
                "save_to_drive(\"models/mingru_weights.pt\", \"mingru.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 4: Mamba-2 Brain (12√ó768d ‚Äî 4 –ø–æ–¥-—Ñ–∞–∑—ã)\n",
                "\n",
                "–û–±—É—á–∞–µ–º—ã–µ –º–æ–¥—É–ª–∏ –ø–æ —Ñ–∞–∑–∞–º:\n",
                "- **Phase 1** (8 —ç–ø–æ—Ö): –í–°–ï ‚Äî SSD, WKV, Œ©-SSM, MoLE, WaveConsolidation\n",
                "- **Phase 2** (5 —ç–ø–æ—Ö): WKV + Fusion + Œ©-SSM + MoLE + NoveltyGate (SSD frozen)\n",
                "- **Phase 3** (3 —ç–ø–æ—Ö–∏): MoLE routing + MatrixPool + WaveConsolidation + NoveltyGate\n",
                "- **Phase 4** (3 —ç–ø–æ—Ö–∏): WKV + RAG + Memory injection + Spine\n",
                "\n",
                "~3-5 —á–∞—Å–æ–≤ –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, os\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0)} ({VRAM_GB:.0f} GB)\")\n",
                "print(f\"Batch: {BATCH} √ó {ACCUM} = {BATCH * ACCUM} effective\")\n",
                "\n",
                "# Transfer embedding MinGRU ‚Üí Mamba-2\n",
                "emb_args = \"\"\n",
                "mingru_path = os.path.join(WORK_DIR, \"models\", \"mingru_weights.pt\")\n",
                "if os.path.exists(mingru_path):\n",
                "    cp = torch.load(mingru_path, map_location='cpu', weights_only=False)\n",
                "    state = cp.get('model_state_dict', cp)\n",
                "    for k in state:\n",
                "        if 'shared_embedding' in k or 'emb.weight' in k:\n",
                "            emb_dir = os.path.join(WORK_DIR, \"models\", \"tars_v3\")\n",
                "            os.makedirs(emb_dir, exist_ok=True)\n",
                "            emb_path = os.path.join(emb_dir, \"_transfer_embedding.pt\")\n",
                "            torch.save(state[k], emb_path)\n",
                "            emb_args = f\"--pretrained_emb {emb_path}\"\n",
                "            print(f\"üîó Transfer embedding: {state[k].shape}\")\n",
                "            break\n",
                "\n",
                "BASE = f\"--d_model 768 --n_layers 12 --vocab_size 256 --batch {BATCH} --accum_steps {ACCUM} --device {device} --curriculum --label_smoothing 0.1 {emb_args}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Phase 1/4: Full pretrain ‚Äî –í–°–ï –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (8 —ç–ø–æ—Ö)\n",
                "print(\"=\" * 65)\n",
                "print(\"  Phase 1/4: Full pretrain (SSD + WKV + Œ©-SSM + MoLE + WaveConsolidation)\")\n",
                "print(\"=\" * 65)\n",
                "!python training/train_mamba2.py {BASE} --epochs 8 --lr 3e-4 --phase 1 --seq_len 256\n",
                "save_to_drive(\"models/mamba2/mamba2_omega.pt\", \"mamba2_phase1.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Phase 2/4: WKV + Fusion + Œ©-SSM + NoveltyGate (SSD frozen, 5 —ç–ø–æ—Ö)\n",
                "print(\"=\" * 65)\n",
                "print(\"  Phase 2/4: Fine-tune WKV + Fusion + Œ©-SSM + NoveltyGate\")\n",
                "print(\"=\" * 65)\n",
                "!python training/train_mamba2.py {BASE} --epochs 5 --lr 1e-4 --phase 2 --seq_len 512 --resume\n",
                "save_to_drive(\"models/mamba2/mamba2_omega.pt\", \"mamba2_phase2.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Phase 3/4: MoLE + MatrixPool + WaveConsolidation + NoveltyGate (3 —ç–ø–æ—Ö–∏)\n",
                "print(\"=\" * 65)\n",
                "print(\"  Phase 3/4: Fine-tune MoLE + MatrixPool + WaveMerge + NoveltyGate\")\n",
                "print(\"=\" * 65)\n",
                "!python training/train_mamba2.py {BASE} --epochs 3 --lr 3e-5 --phase 3 --seq_len 512 --resume\n",
                "save_to_drive(\"models/mamba2/mamba2_omega.pt\", \"mamba2_phase3.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Phase 4/4: WKV + RAG + Memory + Spine (3 —ç–ø–æ—Ö–∏)\n",
                "print(\"=\" * 65)\n",
                "print(\"  Phase 4/4: Fine-tune WKV + RAG + Memory + to/from_memory_space\")\n",
                "print(\"=\" * 65)\n",
                "!python training/train_mamba2.py {BASE} --epochs 3 --lr 1.5e-5 --phase 4 --seq_len 512 --resume\n",
                "save_to_drive(\"models/mamba2/mamba2_omega.pt\", \"mamba2_final.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 5: –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è BitNet 1.58-bit (5 —ç–ø–æ—Ö STE)\n",
                "\n",
                "FP16 ‚Üí 1.58-bit (260 MB ‚Üí ~60 MB). STE (Straight-Through Estimator) –æ–±—É—á–∞–µ—Ç –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å.\n",
                "\n",
                "**–£–≤–µ–ª–∏—á–µ–Ω–æ —Å 3‚Üí5 —ç–ø–æ—Ö** ‚Äî –º–æ–¥–µ–ª—å –ª—É—á—à–µ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ 1.58-bit –≤–µ—Å–∞–º.\n",
                "\n",
                "~20 –º–∏–Ω"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fp16_path = os.path.join(WORK_DIR, \"models\", \"mamba2\", \"mamba2_omega.pt\")\n",
                "\n",
                "if os.path.exists(fp16_path):\n",
                "    fp16_mb = os.path.getsize(fp16_path) / 1024 / 1024\n",
                "    print(\"=\" * 65)\n",
                "    print(f\"  –§–∞–∑–∞ 5: –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è BitNet 1.58-bit (FP16: {fp16_mb:.0f} MB)\")\n",
                "    print(\"=\" * 65)\n",
                "    !python training/train_mamba2.py \\\n",
                "        --d_model 768 --n_layers 12 \\\n",
                "        --batch {BATCH} --accum_steps {ACCUM} \\\n",
                "        --epochs 5 --lr 5e-5 \\\n",
                "        --phase 1 --quant \\\n",
                "        --resume --device cuda \\\n",
                "        --seq_len 256 --label_smoothing 0.1\n",
                "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ò FP16 –∏ 158bit –Ω–∞ Drive\n",
                "    save_to_drive(\"models/mamba2/mamba2_omega.pt\", \"mamba2_fp16.pt\")\n",
                "    save_to_drive(\"models/mamba2/mamba2_omega_158bit.pt\", \"mamba2_158bit.pt\")\n",
                "else:\n",
                "    print(\"‚ö† FP16 –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 7: –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–∑–≥–∞"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, sys\n",
                "sys.path.insert(0, WORK_DIR)\n",
                "\n",
                "print(\"=\" * 65)\n",
                "print(\"  –§–∞–∑–∞ 7: –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–∑–≥–∞\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "try:\n",
                "    from brain.tokenizer import TarsTokenizer\n",
                "    from brain.mamba2.model import TarsMamba2LM\n",
                "\n",
                "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "    tokenizer = TarsTokenizer()\n",
                "    model, ckpt = TarsMamba2LM.load_pretrained(device=device)\n",
                "    model.eval()\n",
                "\n",
                "    if ckpt is None:\n",
                "        print(\"‚ö† Trained weights not found\")\n",
                "    else:\n",
                "        params = sum(p.numel() for p in model.parameters())\n",
                "        print(f\"‚úÖ Model: {ckpt}\")\n",
                "        print(f\"‚úÖ Parameters: {params:,}\")\n",
                "        print()\n",
                "\n",
                "        for prompt in [\"–ø—Ä–∏–≤–µ—Ç\", \"–∫–∞–∫ –¥–µ–ª–∞\", \"—á—Ç–æ —Ç–∞–∫–æ–µ\", \"—Ä–∞—Å—Å–∫–∞–∂–∏\", \"–ø–æ–º–æ–≥–∏\"]:\n",
                "            tokens = tokenizer.encode(prompt)\n",
                "            input_ids = torch.tensor([tokens], dtype=torch.long, device=device)\n",
                "            with torch.no_grad():\n",
                "                logits = model(input_ids)\n",
                "            probs = torch.softmax(logits[0, -1, :], dim=-1)\n",
                "            top5 = torch.topk(probs, 5)\n",
                "            preds = []\n",
                "            for idx, prob in zip(top5.indices.tolist(), top5.values.tolist()):\n",
                "                char = tokenizer.decode([idx])\n",
                "                preds.append(f\"'{char}'({prob:.2%})\")\n",
                "            print(f\"  '{prompt}' ‚Üí {', '.join(preds)}\")\n",
                "\n",
                "        print(\"\\n‚úÖ Brain works!\")\n",
                "    del model\n",
                "    torch.cuda.empty_cache()\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Validation error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üé§ –ì–û–õ–û–° ‚Äî –§–∞–∑—ã 8-10\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 8: Whisper STT ‚Äî –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (LoRA)\n",
                "\n",
                "Fine-tune **Whisper base** (74M) –Ω–∞ —Ä—É—Å—Å–∫–æ–º —á–µ—Ä–µ–∑ LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã.\n",
                "\n",
                "**Whisper base** ‚Äî 2√ó –ª—É—á—à–µ —á–µ–º tiny –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.\n",
                "\n",
                "–î–∞–Ω–Ω—ã–µ: **Common Voice Russian** (10K –ø—Ä–∏–º–µ—Ä–æ–≤, 5 —ç–ø–æ—Ö)\n",
                "\n",
                "~40 –º–∏–Ω –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 65)\n",
                "print(f\"  –§–∞–∑–∞ 8: Whisper {WHISPER_MODEL} LoRA Fine-tune (Russian STT)\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "import gc, torch\n",
                "gc.collect()\n",
                "torch.cuda.empty_cache()\n",
                "\n",
                "!python training/train_whisper.py \\\n",
                "    --model {WHISPER_MODEL} \\\n",
                "    --device cuda \\\n",
                "    --samples 10000 \\\n",
                "    --val_samples 1000 \\\n",
                "    --epochs 5 \\\n",
                "    --batch {WHISPER_BATCH} \\\n",
                "    --lr 1e-3 \\\n",
                "    --lora_r 32\n",
                "\n",
                "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ –Ω–∞ Drive\n",
                "whisper_dir = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_ru_lora\")\n",
                "if os.path.exists(whisper_dir):\n",
                "    drive_whisper = os.path.join(DRIVE_DIR, \"whisper_ru_lora\") if SAVE_TO_DRIVE else None\n",
                "    if drive_whisper:\n",
                "        import shutil\n",
                "        if os.path.exists(drive_whisper):\n",
                "            shutil.rmtree(drive_whisper)\n",
                "        shutil.copytree(whisper_dir, drive_whisper)\n",
                "        print(f\"  üíæ ‚Üí Drive: whisper_ru_lora/\")\n",
                "    print(\"‚úÖ Whisper STT –æ–±—É—á–µ–Ω!\")\n",
                "else:\n",
                "    print(\"‚ö† Whisper LoRA –Ω–µ –Ω–∞–π–¥–µ–Ω\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 9: Piper TTS ‚Äî –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ (VITS)\n",
                "\n",
                "Fine-tune **Piper TTS** –Ω–∞ RUSLAN (31—á —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏).\n",
                "\n",
                "~1-2 —á–∞—Å–∞ –Ω–∞ T4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 65)\n",
                "print(\"  –§–∞–∑–∞ 9: Piper TTS Fine-tune (Russian Voice)\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "gc.collect()\n",
                "torch.cuda.empty_cache()\n",
                "\n",
                "!pip install -q piper-tts piper-phonemize 2>/dev/null || echo \"piper install skipped\"\n",
                "\n",
                "!python training/train_piper.py \\\n",
                "    --epochs 1000 \\\n",
                "    --max_samples 3000 \\\n",
                "    --batch {PIPER_BATCH}\n",
                "\n",
                "piper_onnx = os.path.join(WORK_DIR, \"models\", \"voice\", \"tars_voice_ru.onnx\")\n",
                "if os.path.exists(piper_onnx):\n",
                "    save_to_drive(piper_onnx, \"tars_voice_ru.onnx\")\n",
                "    print(\"‚úÖ Piper TTS –æ–±—É—á–µ–Ω!\")\n",
                "else:\n",
                "    print(\"‚ö† Piper ONNX –Ω–µ —Å–æ–∑–¥–∞–Ω\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## –§–∞–∑–∞ 10: Whisper Boost + Voice INT8 –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è\n",
                "\n",
                "~5 –º–∏–Ω"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 65)\n",
                "print(\"  –§–∞–∑–∞ 10: Whisper Boost + Voice INT8 –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "print(\"\\nüìù Whisper Boost: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤...\")\n",
                "!python training/whisper_boost.py\n",
                "\n",
                "whisper_ctx = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_context.json\")\n",
                "if os.path.exists(whisper_ctx):\n",
                "    save_to_drive(whisper_ctx, \"whisper_context.json\")\n",
                "\n",
                "print(\"\\nüîß INT8 –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...\")\n",
                "!python training/quantize_voice.py\n",
                "\n",
                "print(\"\\n‚úÖ –ì–æ–ª–æ—Å–æ–≤–æ–π –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à—ë–Ω!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üì¶ –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ + –°–∫–∞—á–∏–≤–∞–Ω–∏–µ\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil, json, time\n",
                "\n",
                "OUTPUT_DIR = \"/content/tars_v3_output\"\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "print(\"=\" * 65)\n",
                "print(\"  –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ tars_v3\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "# –í—Å–µ –º–æ–¥–µ–ª–∏ (FP16 + 158bit + MinGRU + Reflex + Voice)\n",
                "model_files = {\n",
                "    \"mamba2.pt\":        os.path.join(WORK_DIR, \"models\", \"mamba2\", \"mamba2_omega.pt\"),\n",
                "    \"mamba2_158bit.pt\": os.path.join(WORK_DIR, \"models\", \"mamba2\", \"mamba2_omega_158bit.pt\"),\n",
                "    \"mingru.pt\":        os.path.join(WORK_DIR, \"models\", \"mingru_weights.pt\"),\n",
                "    \"reflex.pt\":        os.path.join(WORK_DIR, \"models\", \"reflex\", \"reflex_classifier.pt\"),\n",
                "    \"tars_voice_ru.onnx\": os.path.join(WORK_DIR, \"models\", \"voice\", \"tars_voice_ru.onnx\"),\n",
                "    \"whisper_context.json\": os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_context.json\"),\n",
                "}\n",
                "\n",
                "print(\"\\nüì¶ –ú–æ–¥–µ–ª–∏:\")\n",
                "saved_models = []\n",
                "for name, src in model_files.items():\n",
                "    if os.path.exists(src):\n",
                "        dst = os.path.join(OUTPUT_DIR, name)\n",
                "        shutil.copy2(src, dst)\n",
                "        size_mb = os.path.getsize(dst) / 1024 / 1024\n",
                "        print(f\"  ‚úÖ {name} ({size_mb:.1f} MB)\")\n",
                "        saved_models.append(name)\n",
                "        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–ø–∏—è –Ω–∞ Drive!\n",
                "        save_to_drive(src, name)\n",
                "    else:\n",
                "        print(f\"  ‚è≠ {name} ‚Äî –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
                "\n",
                "# Whisper LoRA\n",
                "whisper_lora_src = os.path.join(WORK_DIR, \"models\", \"voice\", \"whisper_ru_lora\")\n",
                "whisper_lora_dst = os.path.join(OUTPUT_DIR, \"whisper_ru_lora\")\n",
                "if os.path.exists(whisper_lora_src):\n",
                "    if os.path.exists(whisper_lora_dst):\n",
                "        shutil.rmtree(whisper_lora_dst)\n",
                "    shutil.copytree(whisper_lora_src, whisper_lora_dst)\n",
                "    print(f\"  ‚úÖ whisper_ru_lora/ (LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã)\")\n",
                "    saved_models.append(\"whisper_ru_lora/\")\n",
                "\n",
                "# Config\n",
                "config = {\n",
                "    \"version\": \"3.0\",\n",
                "    \"models\": {\n",
                "        \"mamba2\": {\n",
                "            \"params\": {\n",
                "                \"encoding\": \"cp1251\", \"vocab_size\": 256,\n",
                "                \"d_model\": 768, \"n_layers\": 12,\n",
                "                \"n_experts\": 8, \"omega_dim\": 32, \"pool_size\": 48\n",
                "            }\n",
                "        },\n",
                "        \"mingru\": {\"dim\": 512, \"layers\": 6},\n",
                "        \"voice\": {\n",
                "            \"stt\": f\"whisper-{WHISPER_MODEL} + LoRA (Russian)\",\n",
                "            \"tts\": \"piper-vits (Russian)\",\n",
                "            \"boost\": \"whisper_context.json\"\n",
                "        }\n",
                "    },\n",
                "    \"trained_on\": \"Google Colab\",\n",
                "    \"gpu\": GPU_NAME,\n",
                "}\n",
                "with open(os.path.join(OUTPUT_DIR, \"config.json\"), \"w\") as f:\n",
                "    json.dump(config, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "# –ê—Ä—Ö–∏–≤\n",
                "archive_path = \"/content/tars_v3_full\"\n",
                "shutil.make_archive(archive_path, 'gztar', OUTPUT_DIR)\n",
                "archive_file = archive_path + \".tar.gz\"\n",
                "size_mb = os.path.getsize(archive_file) / 1024 / 1024\n",
                "\n",
                "if SAVE_TO_DRIVE:\n",
                "    shutil.copy2(archive_file, os.path.join(DRIVE_DIR, \"tars_v3_full.tar.gz\"))\n",
                "    print(f\"\\nüíæ –ê—Ä—Ö–∏–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –Ω–∞ Google Drive!\")\n",
                "\n",
                "total_time = time.time() - T_START\n",
                "hours = total_time / 3600\n",
                "\n",
                "print(f\"\\n{'=' * 65}\")\n",
                "print(f\"  –ò–¢–û–ì–ò –û–ë–£–ß–ï–ù–ò–Ø\")\n",
                "print(f\"{'=' * 65}\")\n",
                "print(f\"  ‚è±  –í—Ä–µ–º—è: {hours:.1f} —á–∞—Å–æ–≤ ({total_time:.0f} —Å–µ–∫)\")\n",
                "print(f\"  üì¶ –ú–æ–¥–µ–ª–∏: {len(saved_models)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤\")\n",
                "for m in saved_models:\n",
                "    print(f\"     ‚úÖ {m}\")\n",
                "print(f\"  üìÅ –ê—Ä—Ö–∏–≤: {archive_file} ({size_mb:.1f} MB)\")\n",
                "print(f\"  üíæ Drive: {DRIVE_DIR}\")\n",
                "print(f\"{'=' * 65}\")\n",
                "print(f\"\\n  üéØ –¢–ê–†–° v3 –ü–û–õ–ù–û–°–¢–¨–Æ –û–ë–£–ß–ï–ù!\")\n",
                "print(f\"  üöÄ –°–∫–æ–ø–∏—Ä—É–π—Ç–µ models/ –≤ –ø—Ä–æ–µ–∫—Ç –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python launch_tars.py\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –°–∫–∞—á–∞—Ç—å –∞—Ä—Ö–∏–≤\n",
                "from google.colab import files\n",
                "files.download(\"/content/tars_v3_full.tar.gz\")"
            ]
        }
    ]
}