"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  –¢–ê–†–° v3 ‚Äî Colab Training (Medium, 103M params)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–û–±—É—á–µ–Ω–∏–µ –Ω–∞ Google Colab —Å –∞–≤—Ç–æ-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–æ–¥ GPU.
–í–°–ï –î–ê–ù–ù–´–ï —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞ Google Drive ‚Äî –Ω–µ —Ç–µ—Ä—è—é—Ç—Å—è –ø—Ä–∏ Disconnect.

  A100 (40GB) ‚Äî batch=–∞–≤—Ç–æ(~1024), bf16, ~15-25 –º–∏–Ω  üî• –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
  L4   (24GB) ‚Äî batch=–∞–≤—Ç–æ(~512),  bf16, ~25-40 –º–∏–Ω  ‚ö° –õ—É—á—à–∏–π –±–∞–ª–∞–Ω—Å
  T4   (15GB) ‚Äî batch=–∞–≤—Ç–æ(~256),  fp16, ~40-60 –º–∏–Ω  ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π

–ò–ù–°–¢–†–£–ö–¶–ò–Ø:
  1. Runtime ‚Üí Change runtime type ‚Üí L4
  2. –ó–∞–ø—É—Å—Ç–∏—Ç—å —è—á–µ–π–∫–∏ –±–ª–æ–∫–Ω–æ—Ç–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É
  3. !python colab_train.py

–û–ü–¶–ò–ò:
  !python colab_train.py --resume           # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞
  !python colab_train.py --skip-download    # –î–∞–Ω–Ω—ã–µ —É–∂–µ –µ—Å—Ç—å
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

import os
import sys
import time
import subprocess
import shutil
from pathlib import Path

# Fix encoding
if hasattr(sys.stdout, 'reconfigure'):
    try:
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    except Exception:
        pass

ROOT = Path(__file__).resolve().parent
os.chdir(ROOT)
sys.path.insert(0, str(ROOT))

IS_COLAB = "COLAB_GPU" in os.environ or os.path.exists("/content")
PYTHON = sys.executable

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 1. Google Drive ‚Äî –í–°–Å —Ö—Ä–∞–Ω–∏—Ç—Å—è –∑–¥–µ—Å—å
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

DRIVE_BASE = None
DRIVE_DATA = None
DRIVE_MODELS = None

if IS_COLAB:
    if Path("/content/drive/MyDrive").exists():
        DRIVE_BASE = Path("/content/drive/MyDrive")
        DRIVE_DATA = DRIVE_BASE / "TarsData"
        DRIVE_MODELS = DRIVE_BASE / "TarsModels"
        DRIVE_DATA.mkdir(parents=True, exist_ok=True)
        DRIVE_MODELS.mkdir(parents=True, exist_ok=True)
        
        # === Symlink: data/ ‚Üí Drive/TarsData ===
        # –î–∞—Ç–∞—Å–µ—Ç—ã —Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –°–†–ê–ó–£ –Ω–∞ Drive!
        local_data = ROOT / "data"
        if local_data.is_symlink():
            pass  # —É–∂–µ —Å–∏–º–ª–∏–Ω–∫
        else:
            if local_data.exists():
                # –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã –Ω–∞ Drive
                for f in local_data.glob("*.txt"):
                    dest = DRIVE_DATA / f.name
                    if not dest.exists():
                        shutil.move(str(f), str(dest))
                for f in local_data.glob("*.json"):
                    dest = DRIVE_DATA / f.name
                    if not dest.exists():
                        shutil.move(str(f), str(dest))
                shutil.rmtree(str(local_data))
            local_data.symlink_to(DRIVE_DATA)
        
        # === Symlink: models/ ‚Üí Drive/TarsModels ===
        local_models = ROOT / "models"
        if local_models.is_symlink():
            pass
        else:
            if local_models.exists():
                for f in local_models.rglob("*"):
                    if f.is_file():
                        rel = f.relative_to(local_models)
                        dest = DRIVE_MODELS / rel
                        dest.parent.mkdir(parents=True, exist_ok=True)
                        if not dest.exists():
                            shutil.move(str(f), str(dest))
                shutil.rmtree(str(local_models))
            local_models.symlink_to(DRIVE_MODELS)
        
        # === LEANN int8 index ‚Üí Drive/TarsMemory ===
        # memory/ —Å–æ–¥–µ—Ä–∂–∏—Ç .py –∫–æ–¥, –Ω–µ–ª—å–∑—è symlink –≤—Å—é –ø–∞–ø–∫—É!
        # –°–æ–∑–¥–∞—ë–º symlink-–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö (npz, json)
        DRIVE_MEMORY = DRIVE_BASE / "TarsMemory"
        DRIVE_MEMORY.mkdir(parents=True, exist_ok=True)
        local_memory = ROOT / "memory"
        local_memory.mkdir(exist_ok=True)
        
        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ LEANN –¥–∞–Ω–Ω—ã–µ –Ω–∞ Drive
        for ext in ("*.npz", "*.json", "*.index"):
            for f in local_memory.glob(ext):
                dest = DRIVE_MEMORY / f.name
                if not dest.exists():
                    shutil.move(str(f), str(dest))
                elif f.exists() and not f.is_symlink():
                    f.unlink()
        
        # –°–æ–∑–¥–∞—ë–º symlink: memory/leann.npz ‚Üí Drive/TarsMemory/leann.npz
        for leann_file in ("leann.npz", "leann.texts.json"):
            local_f = local_memory / leann_file
            drive_f = DRIVE_MEMORY / leann_file
            if not local_f.exists() and not local_f.is_symlink():
                # –°–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –Ω–∞ Drive –µ—Å–ª–∏ –µ—â—ë –Ω–µ—Ç
                if not drive_f.exists():
                    drive_f.touch()
                local_f.symlink_to(drive_f)
        
        print(f"  ‚òÅÔ∏è  Google Drive –ø–æ–¥–∫–ª—é—á—ë–Ω")
        print(f"     data/   ‚Üí {DRIVE_DATA}")
        print(f"     models/ ‚Üí {DRIVE_MODELS}")
        print(f"     LEANN   ‚Üí {DRIVE_MEMORY}")
        
        # –ü–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ —É–∂–µ –µ—Å—Ç—å –Ω–∞ Drive
        existing_data = list(DRIVE_DATA.glob("hf_*.txt"))
        if existing_data:
            total_mb = sum(f.stat().st_size for f in existing_data) / (1024*1024)
            print(f"     üìÇ –ù–∞ Drive —É–∂–µ {len(existing_data)} –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ ({total_mb:.0f} MB)")
    else:
        print("  ‚ö†Ô∏è  Drive –Ω–µ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω!")
        print("     drive.mount('/content/drive')")
        print("     –ë–µ–∑ Drive –¥–∞–Ω–Ω—ã–µ –ü–û–¢–ï–†–Ø–Æ–¢–°–Ø –ø—Ä–∏ Disconnect!")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 2. GPU Detection
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print()
print("‚ïê" * 65)
print("  ü§ñ –¢–ê–†–° v3 ‚Äî MEDIUM TRAINING (Colab)")
print("‚ïê" * 65)
print()

gpu_tier = "t4"
bf16_ok = False
vram = 0

try:
    import torch
    if torch.cuda.is_available():
        gpu = torch.cuda.get_device_name(0)
        vram = torch.cuda.get_device_properties(0).total_memory / 1024**3
        bf16_ok = torch.cuda.get_device_capability(0) >= (8, 0)
        print(f"  üéÆ GPU:    {gpu}")
        print(f"  üíæ VRAM:   {vram:.1f} GB")
        print(f"  ‚ö° bf16:   {'Yes' if bf16_ok else 'No (fp16)'}")
        
        if vram >= 35:
            gpu_tier = "a100"
            print(f"  üî• A100/H100 ‚Üí batch=32, bf16, ~30-45 –º–∏–Ω")
        elif vram >= 20:
            gpu_tier = "l4"
            print(f"  ‚ö° L4/RTX ‚Üí batch=24, bf16, ~45-60 –º–∏–Ω")
        elif vram >= 14:
            gpu_tier = "t4"
            print(f"  ‚úÖ T4 ‚Üí batch=16, fp16, ~1-2 —á–∞—Å–∞")
        else:
            gpu_tier = "small"
            print(f"  ‚ö†Ô∏è  –ú–∞–ª–µ–Ω—å–∫–∏–π VRAM ‚Äî batch=8")
    else:
        print("  ‚ö†Ô∏è  GPU –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("  üîß Runtime ‚Üí Change runtime type ‚Üí L4")
        sys.exit(1)
except ImportError:
    print("  üì¶ PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 3. LEANN ‚Äî –ø—Ä–æ–ø—É—Å–∫ –µ—Å–ª–∏ –Ω–µ—Ç –∏–Ω–¥–µ–∫—Å–∞
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

leann_index = ROOT / "memory" / "leann.index"
if not leann_index.exists():
    leann_index.parent.mkdir(parents=True, exist_ok=True)
    leann_index.touch()
    print("  üß† LEANN: —Å–æ–∑–¥–∞–Ω –ø—É—Å—Ç–æ–π –∏–Ω–¥–µ–∫—Å (–ø—Ä–æ–ø—É—Å–∫)")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 4. Training
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

configs = {
    "a100": {"batch": 32, "accum": 1, "amp": "bf16",  "time": "30-45 –º–∏–Ω"},
    "l4":   {"batch": 24, "accum": 1, "amp": "bf16",  "time": "45-60 –º–∏–Ω"},
    "t4":   {"batch": 16, "accum": 2, "amp": "fp16",  "time": "1-2 —á–∞—Å–∞"},
    "small":{"batch": 8,  "accum": 4, "amp": "fp16",  "time": "2-4 —á–∞—Å–∞"},
}
cfg = configs[gpu_tier]

print()
print(f"  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–∞–≤—Ç–æ-{gpu_tier.upper()}):")
print(f"    –ú–æ–¥–µ–ª—å:        512d √ó 8 —Å–ª–æ—ë–≤ (~103M params)")
print(f"    Batch:         {cfg['batch']} √ó {cfg['accum']} = {cfg['batch']*cfg['accum']} effective")
print(f"    AMP:           {cfg['amp']}")
print(f"    –í—Ä–µ–º—è:         ~{cfg['time']}")
print()
print("‚îÄ" * 65)

t0 = time.time()

# Parse extra args
extra_args = []
for arg in sys.argv[1:]:
    if arg == "--resume":
        extra_args.append("--skip-download")  # resume = –ø—Ä–æ–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    elif arg in ("--skip-download", "--skip-quantize"):
        extra_args.append(arg)

# mega_train.py —Å–∞–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç GPU
cmd = [PYTHON, "mega_train.py", "--skip-voice", "--drive"] + extra_args
result = subprocess.run(cmd, cwd=str(ROOT))

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 5. Report + Resource Monitoring
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

elapsed = time.time() - t0
hours = elapsed / 3600
minutes = elapsed / 60

print()
print("‚ïê" * 65)
if result.returncode == 0:
    print(f"  ‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –∑–∞ {minutes:.0f} –º–∏–Ω ({hours:.1f} —á)!")
    print()
    
    if DRIVE_MODELS:
        total_mb = 0
        for f in DRIVE_MODELS.rglob("*.pt"):
            mb = f.stat().st_size / 1024 / 1024
            total_mb += mb
            print(f"    üíæ {f.name}: {mb:.1f} MB (–Ω–∞ Drive)")
        if total_mb > 0:
            print(f"    {'‚îÄ' * 30}")
            print(f"    –ò—Ç–æ–≥–æ –º–æ–¥–µ–ª–∏: {total_mb:.0f} MB")
    
    print()
    
    # Resource monitoring
    try:
        import psutil
        ram = psutil.virtual_memory()
        print(f"  üìä RAM: {ram.used / 1024**3:.1f}/{ram.total / 1024**3:.1f} GB ({ram.percent}%)")
    except Exception:
        pass
    
    try:
        import torch
        if torch.cuda.is_available():
            alloc = torch.cuda.memory_allocated() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"  üéÆ VRAM: {alloc:.1f}/{total:.1f} GB")
    except Exception:
        pass
    
    # LEANN stats
    leann_npz = ROOT / "memory" / "leann.npz"
    if leann_npz.exists():
        mb = leann_npz.stat().st_size / 1024 / 1024
        print(f"  üß† LEANN: {mb:.0f} MB (int8 embeddings)")
    
    print()
    print(f"  –î–∞–Ω–Ω—ã–µ –Ω–∞ Drive:  MyDrive/TarsData/")
    print(f"  –ú–æ–¥–µ–ª–∏ –Ω–∞ Drive:  MyDrive/TarsModels/")
    print()
    print("  üöÄ –ó–∞–ø—É—Å–∫: python launch_tars.py")
else:
    print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ (–∫–æ–¥ {result.returncode})")
    print(f"     –í—Ä–µ–º—è: {minutes:.0f} –º–∏–Ω")
    print()
    
    # RAM –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî –ø–æ–º–æ–≥–∞–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å OOM
    try:
        import psutil
        ram = psutil.virtual_memory()
        print(f"  üìä RAM: {ram.used / 1024**3:.1f}/{ram.total / 1024**3:.1f} GB ({ram.percent}%)")
    except Exception:
        pass
    
    print()
    print("  –õ–æ–≥–∏: !cat mega_train.log | tail -50")
    print("  –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å: !python colab_train.py --resume")
print("‚ïê" * 65)

