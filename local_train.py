"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Ğ¢ĞĞ Ğ¡ v3 â€” Ğ¡Ğ¢ĞĞ¦Ğ˜ĞĞĞĞ ĞĞĞ• ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ• (Ğ›Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¸Ñ, MAX)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ÑÑ‚Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ°Ñ€Ğ½Ğ¾Ğ¼ GPU (RTX 4090 / 3090 / A6000).
ĞĞ²Ñ‚Ğ¾-Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ GPU â†’ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ¿Ğ¾ VRAM.

  â‰¥22 GB:  768M params (1024d Ã— 20L), batch=4Ã—8=32
  â‰¥14 GB:  400M params (768d Ã— 16L),  batch=4Ã—8=32
  <14 GB:  250M params (768d Ã— 12L),  batch=2Ã—16=32

Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞ˜Ğ•:
  python local_train.py                    # ĞĞ²Ñ‚Ğ¾-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ¿Ğ¾ GPU
  python local_train.py --1b              # Ğ¤Ğ¾Ñ€ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ 768M Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
  python local_train.py --resume          # ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ñ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ°
  python local_train.py --phase 1         # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Phase 1
  python local_train.py --download-only   # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import time
import argparse
import subprocess
import signal
import json
from pathlib import Path
from datetime import datetime

# Fix encoding
if hasattr(sys.stdout, 'reconfigure'):
    try:
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    except Exception:
        pass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. Paths & Constants
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ROOT = Path(__file__).resolve().parent
os.chdir(ROOT)
sys.path.insert(0, str(ROOT))

PYTHON = sys.executable
TRAINING = ROOT / "training"
DATA = ROOT / "data"
MODELS = ROOT / "models"
CHECKPOINTS = MODELS / "checkpoints"
TARS_V3 = MODELS / "tars_v3"
LOG_FILE = ROOT / "local_train.log"
STATE_FILE = ROOT / "train_state.json"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. Arguments
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

parser = argparse.ArgumentParser(description="Ğ¢ĞĞ Ğ¡ v3 â€” Local Training (RTX 4090)")
parser.add_argument("--1b", dest="one_billion", action="store_true",
                    help="Ğ¤Ğ¾Ñ€ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ 1B Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (1024d Ã— 20L)")
parser.add_argument("--resume", action="store_true",
                    help="ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ñ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ°")
parser.add_argument("--phase", type=int, default=None,
                    help="Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ÑƒÑ Ñ„Ğ°Ğ·Ñƒ (1-7)")
parser.add_argument("--download-only", action="store_true",
                    help="Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ")
parser.add_argument("--skip-download", action="store_true",
                    help="ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ (Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞµÑÑ‚ÑŒ)")
parser.add_argument("--skip-voice", action="store_true",
                    help="ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸")
parser.add_argument("--data-preset", default="max",
                    choices=["all", "max", "quality", "massive", "reasoning"],
                    help="ĞšĞ°ĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒ (default: max)")
parser.add_argument("--checkpoint-interval", type=int, default=1800,
                    help="Ğ˜Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ² Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ… (default: 1800 = 30 Ğ¼Ğ¸Ğ½)")
args = parser.parse_args()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. GPU Detection + Auto-Config
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_gpu():
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ GPU Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ (name, vram_gb, device, bf16)."""
    try:
        import torch
        if not torch.cuda.is_available():
            return None, 0, "cpu", False
        
        gpu_name = torch.cuda.get_device_name(0)
        vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        # Check bf16 support (Ampere+)
        bf16_ok = torch.cuda.get_device_capability(0) >= (8, 0)
        
        return gpu_name, vram_gb, "cuda", bf16_ok
    except Exception:
        return None, 0, "cpu", False


def get_config(vram_gb, force_1b=False):
    """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ¿Ğ¾ VRAM."""
    if force_1b or vram_gb >= 22:
        return {
            "name": "768M",
            "d_model": 1024,
            "n_layers": 20,
            "batch": 4,
            "accum": 8,         # effective batch = 32
            "seq_len_start": 512,
            "seq_len_mid": 1024,
            "seq_len_max": 4096,
            "lr_p1": 3e-4,
            "lr_p2": 1e-4,
            "lr_p3": 3e-5,
            "lr_p4": 1.5e-5,
            "lr_p5": 5e-5,
            "epochs_p1": 10,
            "epochs_p2": 5,
            "epochs_p3": 3,
            "epochs_p4": 3,
            "epochs_p5": 5,     # personality
        }
    elif vram_gb >= 14:
        return {
            "name": "400M",
            "d_model": 768,
            "n_layers": 16,
            "batch": 4,
            "accum": 8,
            "seq_len_start": 384,
            "seq_len_mid": 512,
            "seq_len_max": 1024,
            "lr_p1": 3e-4,
            "lr_p2": 1e-4,
            "lr_p3": 3e-5,
            "lr_p4": 1.5e-5,
            "lr_p5": 5e-5,
            "epochs_p1": 10,
            "epochs_p2": 5,
            "epochs_p3": 3,
            "epochs_p4": 3,
            "epochs_p5": 3,
        }
    else:
        return {
            "name": "250M",
            "d_model": 768,
            "n_layers": 12,
            "batch": 2,
            "accum": 16,
            "seq_len_start": 256,
            "seq_len_mid": 384,
            "seq_len_max": 512,
            "lr_p1": 3e-4,
            "lr_p2": 1e-4,
            "lr_p3": 3e-5,
            "lr_p4": 1.5e-5,
            "lr_p5": 5e-5,
            "epochs_p1": 10,
            "epochs_p2": 5,
            "epochs_p3": 3,
            "epochs_p4": 3,
            "epochs_p5": 3,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. State Management (resume support)  
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_state():
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."""
    if STATE_FILE.exists():
        with open(STATE_FILE, 'r') as f:
            return json.load(f)
    return {"completed_phases": [], "current_phase": None, "started": None}


def save_state(state):
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."""
    with open(STATE_FILE, 'w') as f:
        json.dump(state, f, indent=2)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. Training Runner
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run(cmd, timeout=None):
    """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼."""
    cmd_str = " ".join(str(c) for c in cmd)
    print(f"  â†’ {cmd_str[:100]}...")
    
    with open(LOG_FILE, 'a', encoding='utf-8') as log:
        log.write(f"\n{'='*60}\n")
        log.write(f"[{datetime.now()}] {cmd_str}\n")
        log.write(f"{'='*60}\n")
    
    try:
        result = subprocess.run(
            [str(c) for c in cmd],
            cwd=str(ROOT),
            timeout=timeout,
        )
        return result.returncode == 0
    except subprocess.TimeoutExpired:
        print(f"  âš ï¸ Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ ({timeout}s)")
        return False
    except KeyboardInterrupt:
        print(f"\n  â¸ ĞŸÑ€ĞµÑ€Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼. Ğ§ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½.")
        return False
    except Exception as e:
        print(f"  âŒ {e}")
        return False


def train_mamba_phase(phase_num, config, device, bf16, extra_args=None):
    """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¾Ğ´Ğ½Ñƒ Ñ„Ğ°Ğ·Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Mamba-2."""
    
    phase_keys = {
        1: ("epochs_p1", "lr_p1", "seq_len_start"),
        2: ("epochs_p2", "lr_p2", "seq_len_mid"),
        3: ("epochs_p3", "lr_p3", "seq_len_max"),
        4: ("epochs_p4", "lr_p4", "seq_len_max"),
        5: ("epochs_p5", "lr_p5", "seq_len_mid"),
    }
    
    epoch_key, lr_key, seq_key = phase_keys[phase_num]
    
    cmd = [
        PYTHON, str(TRAINING / "train_mamba2.py"),
        "--d_model", str(config["d_model"]),
        "--n_layers", str(config["n_layers"]),
        "--vocab_size", "256",
        "--batch", str(config["batch"]),
        "--accum_steps", str(config["accum"]),
        "--epochs", str(config[epoch_key]),
        "--lr", str(config[lr_key]),
        "--seq_len", str(config[seq_key]),
        "--phase", str(phase_num),
        "--device", device,
        "--curriculum",
        "--label_smoothing", "0.1",
        "--grad_ckpt",
    ]
    
    if bf16:
        cmd += ["--bf16"]
    
    if phase_num > 1 or args.resume:
        cmd += ["--resume"]
    
    if extra_args:
        cmd += extra_args
    
    return run(cmd)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. Main Pipeline
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    # Detect hardware
    gpu_name, vram_gb, device, bf16 = detect_gpu()
    
    config = get_config(vram_gb, force_1b=args.one_billion)
    state = load_state()
    
    # Banner
    print()
    print("â•" * 65)
    print("  ğŸ¤– Ğ¢ĞĞ Ğ¡ v3 â€” LOCAL TRAINING")
    print("â•" * 65)
    print()
    print(f"  ğŸ® GPU:    {gpu_name or 'CPU'}")
    print(f"  ğŸ’¾ VRAM:   {vram_gb:.1f} GB")
    print(f"  ğŸ§  Model:  {config['name']} ({config['d_model']}d Ã— {config['n_layers']}L)")
    print(f"  ğŸ“¦ Batch:  {config['batch']} Ã— {config['accum']} = {config['batch'] * config['accum']} effective")
    print(f"  âš¡ bf16:   {'Yes' if bf16 else 'No'}")
    print(f"  ğŸ“ Data:   {args.data_preset}")
    if args.resume:
        print(f"  ğŸ”„ Resume: from checkpoint")
        if state.get("completed_phases"):
            print(f"     Done:   {state['completed_phases']}")
    print()
    print("â”€" * 65)
    
    t0 = time.time()
    results = {}
    
    # â”€â”€ Phase 0: Install dependencies â”€â”€
    if args.phase is None or args.phase == 0:
        print("\n  ğŸ“¦ Phase 0: Dependencies...")
        results["deps"] = run([PYTHON, "mega_train.py", "--phase", "0"])
    
    # â”€â”€ Phase 1: Download data â”€â”€
    if not args.skip_download and (args.phase is None or args.phase == 1 or args.download_only):
        print(f"\n  ğŸ“š Phase 1: Download data (preset: {args.data_preset})...")
        results["download"] = run([
            PYTHON, str(TRAINING / "download_hf_dataset.py"),
            "--preset", args.data_preset,
        ])
        
        # Generate personality corpus
        personality = DATA / "tars_personality_mega.txt"
        if not personality.exists() or personality.stat().st_size < 1_000_000:
            print("\n  ğŸ§  Generating personality corpus...")
            run([PYTHON, str(TRAINING / "generate_tars_corpus.py")])
        
        if args.download_only:
            elapsed = time.time() - t0
            print(f"\n  âœ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞºĞ°Ñ‡Ğ°Ğ½Ñ‹ Ğ·Ğ° {elapsed/60:.0f} Ğ¼Ğ¸Ğ½ÑƒÑ‚")
            return
    
    # â”€â”€ Phase 2: Reflex classifier â”€â”€
    if args.phase is None or args.phase == 2:
        if "reflex" not in state.get("completed_phases", []):
            print("\n  ğŸ” Phase 2: Reflex classifier (100 epochs)...")
            ok = run([PYTHON, "mega_train.py", "--phase", "2"])
            results["reflex"] = ok
            if ok:
                state.setdefault("completed_phases", []).append("reflex")
                save_state(state)
    
    # â”€â”€ Phase 3: MinGRU LM â”€â”€
    if args.phase is None or args.phase == 3:
        if "mingru" not in state.get("completed_phases", []):
            print("\n  ğŸ§ª Phase 3: MinGRU LM (25 epochs)...")
            ok = run([PYTHON, "mega_train.py", "--phase", "3"])
            results["mingru"] = ok
            if ok:
                state.setdefault("completed_phases", []).append("mingru")
                save_state(state)
    
    # â•â•â• Phase 4: Mamba-2 Brain â€” THE MAIN EVENT â•â•â•
    for mamba_phase in [1, 2, 3, 4]:
        phase_key = f"mamba_p{mamba_phase}"
        if args.phase is not None and args.phase != 4:
            continue
        if phase_key in state.get("completed_phases", []):
            print(f"\n  â­ Phase 4.{mamba_phase}: already done")
            continue
        
        phase_names = {
            1: "Full Pretrain",
            2: "WKV + Fusion Fine-tune",
            3: "MoLE + MatrixPool",
            4: "RAG + Memory Integration",
        }
        
        print(f"\n  ğŸ§  Phase 4.{mamba_phase}: {phase_names[mamba_phase]}...")
        print(f"     {config['d_model']}d Ã— {config['n_layers']}L, "
              f"batch={config['batch']}Ã—{config['accum']}")
        
        ok = train_mamba_phase(mamba_phase, config, device, bf16)
        results[phase_key] = ok
        
        if ok:
            state.setdefault("completed_phases", []).append(phase_key)
            save_state(state)
            print(f"  âœ… Phase 4.{mamba_phase} done, checkpoint saved")
        else:
            print(f"  âš ï¸ Phase 4.{mamba_phase} failed, run with --resume to retry")
            break
    
    # â”€â”€ Phase 5: PersonalityAdapter â”€â”€
    if args.phase is None or args.phase == 5:
        if "personality" not in state.get("completed_phases", []):
            print(f"\n  ğŸ­ Phase 5: PersonalityAdapter ({config['epochs_p5']} epochs)...")
            ok = train_mamba_phase(5, config, device, bf16)
            results["personality"] = ok
            if ok:
                state.setdefault("completed_phases", []).append("personality")
                save_state(state)
    
    # â”€â”€ Phase 6: Second Pass (longer context) â”€â”€
    if args.phase is None or args.phase == 6:
        if "second_pass" not in state.get("completed_phases", []):
            print(f"\n  ğŸ”„ Phase 6: Second Pass (seq_len={config['seq_len_max']})...")
            # Retrain Phase 1 with longer sequences
            cmd = [
                PYTHON, str(TRAINING / "train_mamba2.py"),
                "--d_model", str(config["d_model"]),
                "--n_layers", str(config["n_layers"]),
                "--vocab_size", "256",
                "--batch", str(config["batch"]),
                "--accum_steps", str(config["accum"]),
                "--epochs", "5",
                "--lr", "5e-5",
                "--seq_len", str(config["seq_len_max"]),
                "--phase", "1",
                "--device", device,
                "--curriculum",
                "--label_smoothing", "0.05",
                "--grad_ckpt",
                "--resume",
            ]
            if bf16:
                cmd += ["--bf16"]
            
            ok = run(cmd)
            results["second_pass"] = ok
            if ok:
                state.setdefault("completed_phases", []).append("second_pass")
                save_state(state)
    
    # â”€â”€ Phase 7: Quantize + Validate â”€â”€
    if args.phase is None or args.phase == 7:
        print("\n  âš—ï¸ Phase 7: Quantize 1.58-bit...")
        results["quantize"] = run([PYTHON, "mega_train.py", "--phase", "5"])
        
        print("\n  ğŸ“¦ Phase 7b: Consolidate...")
        results["consolidate"] = run([PYTHON, "mega_train.py", "--phase", "6"])
        
        print("\n  âœ… Phase 7c: Validate...")
        results["validate"] = run([PYTHON, "mega_train.py", "--phase", "7"])
    
    # â”€â”€ Voice (optional) â”€â”€
    if not args.skip_voice and (args.phase is None or args.phase == 8):
        print("\n  ğŸ™ Phase 8: Voice (Whisper + Piper)...")
        run([PYTHON, "mega_train.py", "--phase", "8"])
        run([PYTHON, "mega_train.py", "--phase", "9"])
        run([PYTHON, "mega_train.py", "--phase", "10"])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Results
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    elapsed = time.time() - t0
    hours = elapsed / 3600
    
    print()
    print("â•" * 65)
    print(f"  ğŸ¤– Ğ¢ĞĞ Ğ¡ v3 â€” Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« ({hours:.1f} Ñ‡Ğ°ÑĞ¾Ğ²)")
    print("â•" * 65)
    print()
    
    for name, ok in results.items():
        icon = "âœ…" if ok else "âŒ"
        print(f"    {icon} {name}")
    
    print()
    
    all_ok = all(results.values())
    if all_ok:
        print(f"  ğŸ¯ Ğ’Ğ¡Ğ• Ğ¤ĞĞ—Ğ« Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ«!")
        print(f"  ğŸ“ ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {config['name']} ({config['d_model']}d Ã— {config['n_layers']}L)")
        print()
        
        if TARS_V3.exists():
            total_mb = 0
            for f in TARS_V3.glob("*.pt"):
                mb = f.stat().st_size / 1024 / 1024
                total_mb += mb
                print(f"    {f.name}: {mb:.1f} MB")
            print(f"    {'â”€' * 30}")
            print(f"    Ğ˜Ñ‚Ğ¾Ğ³Ğ¾: {total_mb:.0f} MB")
        
        print()
        print("  ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº: python launch_tars.py")
    else:
        failed = [k for k, v in results.items() if not v]
        print(f"  âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ¸: {', '.join(failed)}")
        print(f"  ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ: python local_train.py --resume")
    
    print()
    print("â•" * 65)


if __name__ == "__main__":
    main()
